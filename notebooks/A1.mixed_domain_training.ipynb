{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 1: Training with Mixed Domain Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation\n",
    "\n",
    "To achieve the desired final output that\n",
    "incorporates features from both domains, we can train\n",
    "the model to learn from both domains simultaneously\n",
    "during the training phase. Our goal is that during\n",
    "testing, when provided with a layer map containing\n",
    "labels from both iOCT and OCT, the model will be\n",
    "able to retrieve the layer features from OCT and the\n",
    "instruments from iOCT.\n",
    "\n",
    "\n",
    "### Method\n",
    "\n",
    "Using the robust image translation model\n",
    "pix2pix [3], we train our model to learn a mapping\n",
    "from a segmentation map to B-scan layers. During the\n",
    "training phase, we feed samples from both the AROI\n",
    "dataset and the OP dataset to ensure the model learns\n",
    "features from both domains. In the testing phase, the\n",
    "model takes in segmentations containing both instru-\n",
    "ments and layer maps, and is expected to reconstruct B-\n",
    "scans with both features. However, if we directly train\n",
    "the model with mixed-domain data, it will inevitably\n",
    "remember the layer map from the porcine iOCT do-\n",
    "main. This can cause confusion when the model is fed\n",
    "with a segmentation layer map at the test phase, as it\n",
    "may not know which domain of layers to generate. To\n",
    "overcome this issue, we employ two strategies:\n",
    "\n",
    "- Downsampling the OP dataset: As there is\n",
    "a significant imbalance between the domains,\n",
    "with the iOCT domain having 11,025 labeled\n",
    "segmentation-B-scan pairs, while the OCT do-\n",
    "main only has 1136, we downsample the OP\n",
    "dataset. This ensures that the model learns the\n",
    "appearance of layers from more OCT images. As\n",
    "the instruments only appear in the iOCT image, a\n",
    "small amount of iOCT B-scans are sufficient for\n",
    "the model to learn their appearance.\n",
    "\n",
    "- Using different segmentation labels for different\n",
    "domains: The model may falsely learn the cor-\n",
    "relation between the visibility of the instrument\n",
    "and the appearance of the layers, reconstructing\n",
    "cross-sectional OCT layers according to the iOCT\n",
    "domain when there are instruments in the scene.\n",
    "To mitigate this problem, we use different layer\n",
    "map labels in different domains, even when the\n",
    "layers are anatomically the same. This strategy is\n",
    "also justified by the differences in size and shape\n",
    "between the fundus of the human eye and that of\n",
    "the porcine eye, despite sharing many similari-\n",
    "ties."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Test Data\n",
    "\n",
    "The test data shoule be the segmentation maps, where the instruments from the iOCT and the layers from the OCT are combined. We create 100 samples for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
