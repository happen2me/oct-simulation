{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5507abea-50d3-450d-8c2c-00ce8e778393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/extra/micheal/IDP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5864a4b-dae3-4a65-9b36-3bbc83cb6902",
   "metadata": {},
   "source": [
    "# Preicise cut and paste"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ba3e25d",
   "metadata": {},
   "source": [
    "In this notebook, we train the pix2pix model to learn a artifitially combined bscan of OCT and OP, from their combined segmentation labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec61e5a9-1ad9-41f7-9b61-b8c7797e09df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python\n",
    "from collections import namedtuple\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from os.path import join\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from idp_utils.visualization import visualize_segmentation, plot_horizontal\n",
    "from idp_utils.data_handling.mask import expand_label, get_dst_shadow\n",
    "import idp_utils.data_handling.constants as C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabea288-dab8-4f05-a33b-605f2523f623",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Randomly choose source and target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3de9bbb-4aeb-4460-8d58-7f6d83114d3d",
   "metadata": {},
   "source": [
    "Fisrt, we randomly choose a OCT and a iOCT image from the datasets, whose segmentations and bscans will be later combined for training.\n",
    "\n",
    "\n",
    "These codes are moved to `idp_tuils.data_handling.ulabel`\n",
    "\n",
    "```python\n",
    "Label = namedtuple(\"Label\", \"instrument mirror ilm ipl rpe bm\", defaults=(None,)*6)\n",
    "unified_label = Label(instrument=1, mirror=2, ilm=3, ipl=4, rpe=5, bm=6)\n",
    "aroi_label = Label(ilm=19, ipl=57, rpe=171, bm=190)\n",
    "op_label = Label(instrument=2, mirror=4, ilm=1, rpe=3)\n",
    "\n",
    "def unify_label(label, src_labels, dst_labels, remove_list=[]):\n",
    "    \"\"\"Transform values in label from src_labels to dst_labels.\n",
    "    It will return a new label. The original label will be left untouched.\n",
    "    Args:\n",
    "        label (numpy array)\n",
    "        src_labels (namedtuple(Label))\n",
    "        dst_labels (namedtuple(Label))\n",
    "        remove_list (list(int)): all labels in this list will be set to 0\n",
    "    \"\"\"\n",
    "    label_copy = label.copy()\n",
    "    for l in Label._fields:\n",
    "        s_label = getattr(src_labels, l)\n",
    "        d_label = getattr(dst_labels, l)\n",
    "        if s_label is not None and d_label is not None:\n",
    "            label_copy[label == s_label] = d_label\n",
    "    for l in remove_list:\n",
    "        label_copy[label == l] = 0\n",
    "    return label_copy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7eab6c-5637-40da-b68e-174d40483399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from idp_utils.data_handling.ulabel import unified_label, aroi_label, op_label, unify_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2809c9ed-8247-4a9f-830e-69d8c2273510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bscan_label(img_name, bscan_prefix=\"data/ioct/bscans/val/\", label_prefix=\"data/ioct/labels/val/\"):\n",
    "    bscan = Image.open(os.path.join(bscan_prefix, img_name))\n",
    "    label = np.asarray(Image.open(os.path.join(label_prefix, img_name)))\n",
    "    return bscan, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dfd5f5-4b2e-4f3c-9cb4-de9ebb61a24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_crossover(src_bscan, src_label, dst_bscan, dst_label, mask):\n",
    "    cross_bscan = dst_bscan.copy()\n",
    "    cross_bscan[mask] = src_bscan[mask]\n",
    "    cross_label = dst_label.copy()\n",
    "    cross_label[mask] = src_label[mask]\n",
    "    return cross_bscan, cross_label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fc56497",
   "metadata": {},
   "source": [
    "Visualize the intra-operative b-scans (OP dataset) and their segmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd7f4c9-2f2c-4254-9d5e-ed443e9d053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bscan_prefix = os.path.join(C.SPLIT_PATTERN.format(data='ioct'), 'bscans', 'val')\n",
    "label_prefix = os.path.join(C.SPLIT_PATTERN.format(data='ioct'), 'labels', 'val')\n",
    "img_name = \"5d396575-e039-49da-a219-fe239e8bd9c88062-101.png\"\n",
    "\n",
    "src_bscan, src_label = get_bscan_label(img_name, bscan_prefix, label_prefix)\n",
    "src_label=unify_label(src_label, src_labels=op_label, dst_labels=unified_label)\n",
    "visualize_segmentation(src_bscan, src_label, show_original=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e390a44e",
   "metadata": {},
   "source": [
    "Visualize the OCT b-scans (AROI dataset) and their segmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad7e67d-603a-4ed6-88f8-a3ada38cfd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_bscan_prefix = os.path.join(C.SPLIT_PATTERN.format(data='aroi'), 'bscans', 'train') # \"data/aroi/bscans/train/\"\n",
    "dst_label_prefix = os.path.join(C.SPLIT_PATTERN.format(data='aroi'), 'labels', 'train') # \"data/aroi/labels/train/\"\n",
    "dst_img_name = \"patient21_raw0060.png\"  # \"patient15_raw0032.png\"\n",
    "dst_bscan, dst_label = get_bscan_label(dst_img_name, dst_bscan_prefix, dst_label_prefix)\n",
    "dst_label = unify_label(dst_label, src_labels=aroi_label, dst_labels=unified_label, remove_list=[80, 160, 240])\n",
    "visualize_segmentation(dst_bscan, dst_label, show_original=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fed6611c-b6e5-4924-8b83-dea46ae94752",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 1: Manipulate on the bscan\n",
    "\n",
    "The goal is the artifitialy create a cross-over image.\n",
    "\n",
    "To identify which part should be copied from which image, we need to know the location of the instrument and the mirror in the image. We can use the segmentation labels to identify these two parts, by **generating masks** from them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60161ec3-49b8-4a8e-b15a-1b9818d198f1",
   "metadata": {},
   "source": [
    "### Step 1: Copy and paste the tool with the manually expanded mask\n",
    "\n",
    "Such mask is very inaccurate.\n",
    "\n",
    "TODO:\n",
    "- improve mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ca9390-65dc-4244-b8fe-37afa4985cbb",
   "metadata": {},
   "source": [
    "#### 1. Expand instrument and mirroring label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f814507-c393-4d54-87c6-82e9e0354442",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_label = expand_label(src_label,\n",
    "                              instrument_label=unified_label.instrument,\n",
    "                              mirror_label=unified_label.mirror,\n",
    "                              expansion_instrument=30,\n",
    "                              expansion_mirror=0,\n",
    "                              expand_upward=True)\n",
    "plt.imshow(expanded_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9019804f-1915-442b-b36a-e746a9798a04",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. Cover the layers with the target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b55720a-6dcf-47da-a3fa-647dbb7ea52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dst_shadow(src_label, dst_label, instrument_label=2, mirror_label=4,\n",
    "                   top_layer_label=1, margin_above=0, pad_left=0, pad_right=0):\n",
    "    \"\"\"Get the shadow of the source label in the destination label, taking\n",
    "    the instrument and shadow label in the source as well as the layer label\n",
    "    in the destination into account\n",
    "    Args:\n",
    "    overflow_above: the margin to include above the top layer. This is for the cases\n",
    "        that the human labeled top layer is inaccurate and leaves some pixels out.\n",
    "    pad_left: the number of pixels to pad to the left of the shadow. This is for the\n",
    "        that direct under of the instrument actually includes some layers.\n",
    "    pad_right: the number of pixels to pad to the right of the shadow. This is for the\n",
    "        that direct under of the instrument actually includes some layers.\n",
    "    \"\"\"\n",
    "    img_height, img_width = src_label.shape\n",
    "    shadow_x = np.array([], dtype=np.int64)\n",
    "    shadow_y = np.array([], dtype=np.int64)\n",
    "    # Requirements for the shadow label:\n",
    "    # 1. Horizontally after the starting of the instrument/mirroring & before the\n",
    "    #    ending of the instrument/mirroring\n",
    "    # 2. Vertically below the upper bound of layers\n",
    "    x_src_tool, y_src_tool = np.where(np.logical_or(src_label == instrument_label,\n",
    "                    src_label == mirror_label))  # (1024, 512)\n",
    "    if len(x_src_tool) == 0:\n",
    "        return shadow_x, shadow_y\n",
    "    left_bound = np.min(y_src_tool)\n",
    "    right_bound = np.max(y_src_tool)\n",
    "    # Detect left break and right break of the top layer, this is to adjust the left and\n",
    "    # right bound of the shadow.\n",
    "    for y in range(left_bound, img_width):\n",
    "        # If the layer continues to present to the right of left_bound below the tools,\n",
    "        # increase left_bound\n",
    "        if np.any(src_label[:, y] == top_layer_label):\n",
    "            left_bound = y\n",
    "        else:\n",
    "            break\n",
    "    for y in range(right_bound, -1, -1):\n",
    "        # If the layer continues to present to the left of right_bound below the tools,\n",
    "        # decrease right_bound\n",
    "        if np.any(src_label[:, y] == top_layer_label):\n",
    "            right_bound = y\n",
    "        else:\n",
    "            break\n",
    "    if pad_left + left_bound < right_bound:\n",
    "        left_bound += pad_left\n",
    "    if right_bound - pad_left > left_bound:\n",
    "        right_bound -= pad_right\n",
    "    accumulated_min_upperbound = 0\n",
    "    for i in range(left_bound, right_bound):\n",
    "        top_layer = np.where(dst_label[:, i] == top_layer_label)[0]\n",
    "        if len(top_layer) == 0:\n",
    "            if accumulated_min_upperbound == 0:\n",
    "                continue\n",
    "            else:\n",
    "                # set to current recorded highest layer\n",
    "                top_layer_upperbound = accumulated_min_upperbound\n",
    "        else:\n",
    "            # print(\"instrument_above\", instrument_above, len(instrument_above))\n",
    "            top_layer_upperbound = np.min(top_layer)\n",
    "            if top_layer_upperbound - margin_above > 0:\n",
    "                top_layer_upperbound -= margin_above\n",
    "            if accumulated_min_upperbound == 0:\n",
    "                # initialize\n",
    "                accumulated_min_upperbound = top_layer_upperbound\n",
    "            else:\n",
    "                accumulated_min_upperbound = min(\n",
    "                    accumulated_min_upperbound, top_layer_upperbound)\n",
    "        x_vertical = np.arange(top_layer_upperbound,\n",
    "                               img_height)  # upperbound to bottom\n",
    "        y_vertical = np.full_like(x_vertical, i)\n",
    "        shadow_x = np.concatenate([shadow_x, x_vertical])\n",
    "        shadow_y = np.concatenate([shadow_y, y_vertical])\n",
    "    return shadow_x, shadow_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cba313-aba3-465a-80be-511eb9eada7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_x, shadow_y = get_dst_shadow(expanded_label, dst_label, instrument_label=unified_label.instrument,\n",
    "                                    mirror_label=unified_label.mirror, top_layer_label=unified_label.ilm,\n",
    "                                    margin_above=5, pad_left=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dafa838-0acc-4eea-a91b-b6239e8823ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.full(src_label.shape, False)\n",
    "classes_of_interest = [unified_label.instrument, unified_label.mirror]\n",
    "for c in classes_of_interest:\n",
    "    mask[expanded_label==c] = True\n",
    "mask[shadow_x, shadow_y] = True\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30304e39-7584-42b3-b339-562fb9c096a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3. Copy and past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e44cc21-cf7c-4976-b0ca-b4689a6d2af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_bscan = np.asarray(dst_bscan)\n",
    "src_bscan = np.asarray(src_bscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d16f1e-d6fb-4901-8505-6ca0b65f4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_bscan = dst_bscan.copy()\n",
    "cross_bscan[mask] = src_bscan[mask]\n",
    "# cross_bscan = np.ma.array(cross_bscan, mask=mask)\n",
    "plt.imshow(cross_bscan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a0d01d-63be-40a6-ad2d-187e60e3f5f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 2: Manipulate the label\n",
    "\n",
    "The goal of this part is to create the corresponding label for the first part. The intuition is that it is very precise to manipulate on the label map. Then we can generate a image from the manipulated label map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0219796-c511-4285-b9a8-9f90f3f8b291",
   "metadata": {},
   "source": [
    "### 1. Create Cross-over labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc54dfd-503d-4e1c-bcbd-512c766ce07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_bscan, cross_label = create_crossover(src_bscan, src_label, dst_bscan, dst_label, mask)\n",
    "visualize_segmentation(cross_bscan, cross_label, show_original=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee17cd82-60b8-4fe9-bcf4-642b45938f51",
   "metadata": {},
   "source": [
    "### 2. Expand Instrument Labels (Optional) \n",
    "\n",
    "Here I'll expand the instrument and mirroring labels. In previous experiment, we found out that the instruments are blurred.\n",
    "\n",
    "The intuition is that maybe a better coverage of the label helps generate clearer instruments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fcaaa8-8732-4057-b9f6-892c40698622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from idp_utils.data_handling.mask import expand_label\n",
    "from idp_utils.data_handling.ulabel import unified_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957db121-ee16-4ab9-946f-e49684bc2fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_label.instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08d0d39-8538-43e1-ab4a-0b5f0596241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_label = expand_label(cross_label,\n",
    "                              instrument_label=unified_label.instrument,\n",
    "                              mirror_label=unified_label.mirror,\n",
    "                              expansion_instrument=20,\n",
    "                              expansion_mirror=40)\n",
    "plt.imshow(expanded_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2044ed-9e4e-408a-a93b-18c6ef9a332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_segmentation(cross_bscan, expanded_label, show_original=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7811397b-a185-431d-b37a-df8a91150502",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 3: Create a dataset\n",
    "\n",
    "Per requirements to the [pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/datasets.md#pix2pix-datasets), we have to create the dataset and place it using a certain format.\n",
    "\n",
    "The ideal way is to implement a custom sampler [link](https://discuss.pytorch.org/t/how-to-generate-random-pairs-at-each-epoch/112065/2).\n",
    "\n",
    "Here I'll do it in a simpler way.\n",
    "1. Randomly choose a OP and an AROI image\n",
    "2. Create a mask based on the OP and the AROI image\n",
    "3. Make the cross over label and bscan\n",
    "4. Save to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f261aba-52c9-4085-b2c9-1ee8d626ae42",
   "metadata": {},
   "source": [
    "### 1. Create a pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d52a1-8d07-4655-80e7-5db8e486cfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "op_bscan_folder = os.path.join(C.SPLIT_PATTERN.format(data='ioct'), 'bscans')\n",
    "op_label_folder = os.path.join(C.SPLIT_PATTERN.format(data='ioct'), 'labels')\n",
    "aroi_bscan_folder = os.path.join(C.SPLIT_PATTERN.format(data='aroi'), 'bscans')\n",
    "aroi_label_folder = os.path.join(C.SPLIT_PATTERN.format(data='aroi'), 'labels')\n",
    "def sample(src_bscan_prefix, src_label_prefix, dst_bscan_prefix, bscan_label_prefix, n_pairs=1000):\n",
    "    \"\"\"\n",
    "    Sample pairs of source and target images. Source is where we will cut the instruments and\n",
    "    mirrorings, destination is where we want to preserve the layers. The passed in prefixs are\n",
    "    expected to directly contain paired images respectively.\n",
    "    \n",
    "    Returns:\n",
    "        pairs (list(tuple)): a list of tuples of paths [(src_bscan, src_label, dst_bscan, dst_label)]\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    src_bscans = glob(os.path.join(src_bscan_prefix, '*'))\n",
    "    src_labels = glob(os.path.join(src_label_prefix, '*'))\n",
    "    dst_bscans = glob(os.path.join(dst_bscan_prefix, '*'))\n",
    "    dst_labels = glob(os.path.join(dst_label_prefix, '*'))\n",
    "    assert len(src_bscans) == len(src_labels) and len(src_bscans) != 0, f\"Length mismatch for bscans and labels ({len(src_bscans)}!={len(src_labels)})\"\n",
    "    assert len(dst_bscans) == len(dst_labels) and len(dst_bscans) != 0, f\"Length mismatch for bscans and labels ({len(dst_bscans)}!={len(dst_labels)})\"\n",
    "    for _ in tqdm(range(n_pairs)):\n",
    "        src_idx = random.randrange(len(src_bscans))\n",
    "        dst_idx = random.randrange(len(dst_bscans))\n",
    "        src_bscan = src_bscans[src_idx]\n",
    "        src_label = src_labels[src_idx]\n",
    "        dst_bscan = dst_bscans[dst_idx]\n",
    "        dst_label = dst_labels[dst_idx]\n",
    "        pairs.append((src_bscan, src_label, dst_bscan, dst_label))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da1d1be-4658-4bd8-9bf3-50a8daf15eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_pairs = {}\n",
    "for split, n_pairs in zip(['train', 'val', 'test'], [10000, 1000, 1000]):\n",
    "    src_bscan_prefix = join(op_bscan_folder, split)\n",
    "    src_label_prefix = join(op_label_folder , split)\n",
    "    dst_bscan_prefix = join(aroi_bscan_folder, split)\n",
    "    dst_label_prefix = join(aroi_label_folder, split)\n",
    "    sampled_pairs[split] = sample(src_bscan_prefix, src_label_prefix, dst_bscan_prefix, dst_label_prefix, n_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e920fb-19fc-4739-b1f2-88807d868f0a",
   "metadata": {},
   "source": [
    "### 2. Create a mask for a pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a316fe-30d7-4b97-9adf-ec72e4da007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_as_array(img_path, label_type=None):\n",
    "    \"\"\"Load the image from a path to a numpy array\n",
    "    If label type is set, it will convert and unify the label.\n",
    "    label_type accepts None or op or aroi\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path)\n",
    "    img_arr = np.asarray(img)\n",
    "    if label_type == 'op':\n",
    "        img_arr = unify_label(img_arr, src_labels=op_label, dst_labels=unified_label)\n",
    "    elif label_type == 'aroi':\n",
    "        img_arr = unify_label(img_arr, src_labels=aroi_label, dst_labels=unified_label, remove_list=[80, 160, 240])\n",
    "    return img_arr\n",
    "\n",
    "def create_mask(src_bscan, src_label, dst_bscan, dst_label):\n",
    "    # 2. expand source label\n",
    "    expanded_src_label = expand_label(src_label,\n",
    "                                      instrument_label=unified_label.instrument,\n",
    "                                      mirror_label=unified_label.mirror,\n",
    "                                      expansion_instrument=30,\n",
    "                                      expansion_mirror=0,\n",
    "                                      expand_upward=True)\n",
    "    # 3. get shadowed area based on the dst label\n",
    "    shadow_x, shadow_y = get_dst_shadow(expanded_src_label,\n",
    "                                        dst_label,\n",
    "                                        instrument_label=unified_label.instrument,\n",
    "                                        mirror_label=unified_label.mirror,\n",
    "                                        top_layer_label=unified_label.ilm,\n",
    "                                        margin_above=20,\n",
    "                                        pad_left=0,\n",
    "                                        pad_right=0)\n",
    "    # 4. create the mask\n",
    "    mask = np.full(src_bscan.shape, False)\n",
    "    classes_of_interest = [unified_label.instrument, unified_label.mirror]\n",
    "    for c in classes_of_interest:\n",
    "        mask[expanded_src_label==c] = True\n",
    "    mask[shadow_x, shadow_y] = True\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890bca7a-e098-4c2e-91e6-385c9b4d3229",
   "metadata": {},
   "source": [
    "### 3. Create cross over bscan and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e107fd92-5234-4030-b12a-df302f151470",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_pair = sampled_pairs['train'][233]\n",
    "print(sampled_pair)\n",
    "src_bscan_path, src_label_path, dst_bscan_path, dst_label_path = sampled_pair\n",
    "loaded_pair = (\n",
    "    load_as_array(src_bscan_path),\n",
    "    load_as_array(src_label_path, label_type='op'),\n",
    "    load_as_array(dst_bscan_path),\n",
    "    load_as_array(dst_label_path, label_type='aroi')    \n",
    ")\n",
    "mask = create_mask(*loaded_pair)\n",
    "cross_bscan, cross_label = create_crossover(*loaded_pair, mask)\n",
    "# optional: expand cross label\n",
    "# cross_label = expand_label(cross_label,\n",
    "#                            instrument_label=unified_label.instrument,\n",
    "#                            mirror_label=unified_label.mirror,\n",
    "#                            expansion_instrument=20,\n",
    "#                            expansion_mirror=40)\n",
    "visualize_segmentation(cross_bscan, cross_label, show_original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073dade5-a25d-41d7-9c49-539629e5c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_horizontal(loaded_pair+(cross_bscan, cross_label, mask),\n",
    "                ['s_bscan', 's_label', 'd_bscan', 'd_label', 'c_bscan', 'c_label', 'mask'],\n",
    "                figsize=(15, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82832d88-95dc-4d3d-9230-058787b81c33",
   "metadata": {},
   "source": [
    "### 4. Mass produce a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d479d5fd-595f-473e-ae53-db486386c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_dataset_path = C.SPLIT_PATTERN.format(data='cross')\n",
    "for typ in ['bscans', 'labels']:\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        data_dir = join(cross_dataset_path, typ, split)\n",
    "        Path(data_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca3a3c5-03a4-4ff3-ba6b-8a26ea197bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import basename\n",
    "def create_cross_pair(src_bscan_path, src_label_path, dst_bscan_path, dst_label_path, expand=False):\n",
    "    loaded_pair = (\n",
    "        load_as_array(src_bscan_path),\n",
    "        load_as_array(src_label_path, label_type='op'),\n",
    "        load_as_array(dst_bscan_path),\n",
    "        load_as_array(dst_label_path, label_type='aroi')    \n",
    "    )\n",
    "    mask = create_mask(*loaded_pair)\n",
    "    cross_bscan, cross_label = create_crossover(*loaded_pair, mask)\n",
    "    if expand:\n",
    "        cross_label = expand_label(cross_label,\n",
    "                                   instrument_label=unified_label.instrument,\n",
    "                                   mirror_label=unified_label.mirror,\n",
    "                                   expansion_instrument=20,\n",
    "                                   expansion_mirror=40)\n",
    "    return cross_bscan, cross_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697ace15-baab-4f6a-95d2-67ab16661e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_cross_dataset_path = C.SPLIT_PATTERN.format(data='cross_large')\n",
    "for typ in ['bscans', 'labels']:\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        data_dir = join(expanded_cross_dataset_path, typ, split)\n",
    "        Path(data_dir).mkdir(parents=True, exist_ok=True)\n",
    "bscan_dir = join(expanded_cross_dataset_path, 'bscans')\n",
    "label_dir = join(expanded_cross_dataset_path, 'labels')\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    sampled_pair = sampled_pairs[split]\n",
    "    for pair in tqdm(sampled_pair):\n",
    "        cross_bscan, cross_label = create_cross_pair(*pair, expand=True)\n",
    "        cross_bscan = Image.fromarray(cross_bscan, mode='L')\n",
    "        cross_label = Image.fromarray(cross_label, mode='L')\n",
    "        img_name = basename(pair[0]).split('.')[-2] + '-' + basename(pair[2]).split('.')[-2] + '.png'\n",
    "        cross_bscan.save(os.path.join(bscan_dir, split, img_name))\n",
    "        cross_label.save(os.path.join(label_dir, split, img_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d620d284-d29f-440a-a5b2-9f76fdac7d21",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 4. Train a pix2pix on the artifitially generated images\n",
    "\n",
    "Check [pix2pix train/test](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix#pix2pix-traintest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ff288a-51e2-42f7-8088-2de8ce50bf74",
   "metadata": {},
   "source": [
    "### 1. Create a dataset with the dataset creation script\n",
    "\n",
    "`python datasets/combine_A_and_B.py --fold_A /path/to/data/A --fold_B /path/to/data/B --fold_AB /path/to/data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50722f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_combined_dir = C.DATASET_PATTERN.format(data='cross_large_pix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2adb1c-123b-4840-8dd2-976f48cf3755",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_combined_dir = C.DATASET_PATTERN.format(data='cross_large_pix')\n",
    "!mkdir -p cross_combined_dir\n",
    "cross_combined_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b018b-78c6-4664-aa18-bb6f6fa116b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf $cross_combined_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b866f108-8b07-4367-9d87-d3c8c45ad94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo label_dir: $label_dir\n",
    "!echo bscan_dir: $bscan_dir\n",
    "!echo cross_combined_dir: $cross_combined_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b5104d-b1e6-4145-ae93-0e51035d60dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py --fold_A $label_dir --fold_B $bscan_dir --fold_AB $cross_combined_dir --grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a226b-3d3d-42b0-89fb-940fa614957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l data/datasets/cross_large_pix/train | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84485700-52de-4a64-833c-da473e1cc788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expaned\n",
    "expanded_cross_combined_dir = C.DATASET_PATTERN.format(data='expanded_cross_pix')\n",
    "!echo label_dir: $label_dir\n",
    "!echo bscan_dir: $bscan_dir\n",
    "!echo expanded_cross_combined_dir: $expanded_cross_combined_dir\n",
    "!python pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py --fold_A $label_dir --fold_B $bscan_dir --fold_AB $expanded_cross_combined_dir --grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60269188-24dd-4d5f-af58-57c73ba9fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_cross_combined_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb9c9d7-3812-49cd-8409-e2848a9d8055",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Train a pix2pix model\n",
    "\n",
    "`python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a522e-971c-428d-a7ba-66a57723cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python pytorch-CycleGAN-and-pix2pix/train.py  --help"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77df7999-5f50-4d56-81b1-4254f0108464",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Vanilla cross label\n",
    "\n",
    "**Intuition**: The desired output is the bscan with part from the AROI and part from the OP. Therefore we can explicitly fabricate the desired output as well as the cross-label input, with simple cut-and-paste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6466801-de1f-4c84-9be0-46de6d0fa61f",
   "metadata": {},
   "source": [
    "--name was `pix_fused`\n",
    "\n",
    "```verbose log\n",
    "----------------- Options ---------------\n",
    "               batch_size: 64                            \t[default: 1]\n",
    "                    beta1: 0.5                           \n",
    "          checkpoints_dir: ./checkpoints                 \n",
    "           continue_train: False                         \n",
    "                crop_size: 256                           \n",
    "                 dataroot: data/datasets/cross_large_pix \t[default: None]\n",
    "             dataset_mode: aligned                       \n",
    "                direction: AtoB                          \n",
    "              display_env: main                          \n",
    "             display_freq: 400                           \n",
    "               display_id: 1                             \n",
    "            display_ncols: 4                             \n",
    "             display_port: 8097                          \n",
    "           display_server: http://localhost              \n",
    "          display_winsize: 256                           \n",
    "                    epoch: latest                        \n",
    "              epoch_count: 1                             \n",
    "                 gan_mode: vanilla                       \n",
    "                  gpu_ids: 0                             \n",
    "                init_gain: 0.02                          \n",
    "                init_type: normal                        \n",
    "                 input_nc: 3                             \n",
    "                  isTrain: True                          \t[default: None]\n",
    "                lambda_L1: 100.0                         \n",
    "                load_iter: 0                             \t[default: 0]\n",
    "                load_size: 286                           \n",
    "                       lr: 0.0002                        \n",
    "           lr_decay_iters: 50                            \n",
    "                lr_policy: linear                        \n",
    "         max_dataset_size: inf                           \n",
    "                    model: pix2pix                       \t[default: cycle_gan]\n",
    "                 n_epochs: 400                           \t[default: 100]\n",
    "           n_epochs_decay: 100                           \n",
    "               n_layers_D: 3                             \n",
    "                     name: cross_large_pix               \t[default: experiment_name]\n",
    "                      ndf: 64                            \n",
    "                     netD: basic                         \n",
    "                     netG: unet_256                      \n",
    "                      ngf: 64                            \n",
    "               no_dropout: False                         \n",
    "                  no_flip: False                         \n",
    "                  no_html: False                         \n",
    "                     norm: batch                         \n",
    "              num_threads: 4                             \n",
    "                output_nc: 3                             \n",
    "                    phase: train                         \n",
    "                pool_size: 0                             \n",
    "               preprocess: resize_and_crop               \n",
    "               print_freq: 500                           \t[default: 100]\n",
    "             save_by_iter: False                         \n",
    "          save_epoch_freq: 20                            \t[default: 5]\n",
    "         save_latest_freq: 5000                          \n",
    "           serial_batches: False                         \n",
    "                   suffix:                               \n",
    "         update_html_freq: 1000                          \n",
    "                use_wandb: False                         \n",
    "                  verbose: False       \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2020f381-a15a-446f-a8fd-6d1911810805",
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=1 python pytorch-CycleGAN-and-pix2pix/train.py \\\n",
    "    --dataroot $cross_combined_dir \\\n",
    "    --name cross_large_pix \\\n",
    "    --model pix2pix \\\n",
    "    --direction AtoB \\\n",
    "    --n_epochs 400 \\\n",
    "    --print_freq 500 \\\n",
    "    --batch_size 64 \\\n",
    "    --save_epoch_freq 20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48a8a708-5f00-4e75-82cc-c8c714f9da43",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Expanded labels\n",
    "\n",
    "**Intuition**: The expanded labels of the instruments covers the areas of the instruments, so that it helps guide the model to generate clearer instruments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09da119-bbaf-4386-9331-f1926935e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with expanded\n",
    "!CUDA_VISIBLE_DEVICES=1 python pytorch-CycleGAN-and-pix2pix/train.py \\\n",
    "    --dataroot $expanded_cross_combined_dir \\\n",
    "    --name \"expanded_pix_fused\" \\\n",
    "    --model pix2pix \\\n",
    "    --direction AtoB \\\n",
    "    --n_epochs 400 \\\n",
    "    --print_freq 500 \\\n",
    "    --batch_size 64 \\\n",
    "    --save_epoch_freq 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ca1ca7-0032-448e-ae09-19763b8f6161",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = 'data/datasets/cross_combined'\n",
    "name = 'onehot_cross_pix'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b18d740-6d6e-4adc-8ea0-8bc26483b29b",
   "metadata": {},
   "source": [
    "#### One-hot input\n",
    "\n",
    "We train a model with `input_nc=n_labels`, `output_nc=1` and `dataset_mode=oct`.\n",
    "\n",
    "The *oct* mode is implemented in the submodule pix2pix.\n",
    "\n",
    "**Intuition**: instead of cluttering the input labels with meaningless sequential numbers in a same channel, we can use one-hot encoding to represent the labels, so that different labels are semantically independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1618c26e-28fa-4b59-9550-5eb409a17ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $dataroot\n",
    "!CUDA_VISIBLE_DEVICES=1 python submodules/pix2pix/train.py \\\n",
    "    --dataroot $dataroot \\\n",
    "    --name $name \\\n",
    "    --model pix2pix \\\n",
    "    --direction AtoB \\\n",
    "    --n_epochs 100 \\\n",
    "    --print_freq 500 \\\n",
    "    --batch_size 64 \\\n",
    "    --save_epoch_freq 20 \\\n",
    "    --input_nc 7 \\\n",
    "    --output_nc 1 \\\n",
    "    --dataset_mode oct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a0355-920b-4691-aad5-aaec81c3c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'onehot_cross_pix_o3'\n",
    "!echo $dataroot\n",
    "!CUDA_VISIBLE_DEVICES=1 python submodules/pix2pix/train.py \\\n",
    "    --dataroot $dataroot \\\n",
    "    --name $name \\\n",
    "    --model pix2pix \\\n",
    "    --direction AtoB \\\n",
    "    --n_epochs 200 \\\n",
    "    --print_freq 500 \\\n",
    "    --batch_size 64 \\\n",
    "    --save_epoch_freq 20 \\\n",
    "    --input_nc 7 \\\n",
    "    --output_nc 3 \\\n",
    "    --dataset_mode oct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43f64fb-e5cd-41bd-ae9f-ff9162ef00a3",
   "metadata": {},
   "source": [
    "## Part 5: Test the Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fae148-7685-46d5-9c0c-e6497f5acb25",
   "metadata": {},
   "source": [
    "Results are saved at `./results/pix_fused/test_{epoch}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c327fcf-4467-491b-94fb-87ec135efb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in [10, 20, 30, 40, 50, 60, 100, 150]:\n",
    "    !CUDA_VISIBLE_DEVICES=1 python pytorch-CycleGAN-and-pix2pix/test.py  \\\n",
    "        --dataroot $cross_combined_dir \\\n",
    "        --name \"pix_fused\" \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB \\\n",
    "        --epoch {ep} \\\n",
    "        --results_dir \"fused_on_combined\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d19b95-5fd3-491f-a310-ce6841014747",
   "metadata": {},
   "source": [
    "Evaluate on iOCT data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2610dbdf-6890-4e05-8f7e-21c8d3e7080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "uop_dataset_dir = C.DATASET_PATTERN.format(data='uop')\n",
    "for ep in [80, 100, 150]:\n",
    "    !CUDA_VISIBLE_DEVICES=1 python pytorch-CycleGAN-and-pix2pix/test.py  \\\n",
    "        --dataroot $uop_dataset_dir \\\n",
    "        --name \"pix_fused\" \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB \\\n",
    "        --epoch {ep} \\\n",
    "        --batch_size 10 \\\n",
    "        --results_dir \"./results/fused_on_ioct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ffd9ac-e8ba-4824-bfbc-d63c44bcc5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "uop_dataset_dir = C.DATASET_PATTERN.format(data='uop')\n",
    "uop_dataset_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b626c8-54f8-415f-ac9b-718262e4f3f8",
   "metadata": {},
   "source": [
    "Evaluate the model with expanded instrument label on iOCT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2f383-aa44-4804-843a-6ece1b143466",
   "metadata": {},
   "outputs": [],
   "source": [
    "uop_dataset_dir = C.DATASET_PATTERN.format(data='uop')\n",
    "for ep in [20, 40, 60, 140, 300]:\n",
    "    !CUDA_VISIBLE_DEVICES=1 python pytorch-CycleGAN-and-pix2pix/test.py  \\\n",
    "        --dataroot $uop_dataset_dir \\\n",
    "        --name \"expanded_pix_fused\" \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB \\\n",
    "        --epoch {ep} \\\n",
    "        --batch_size 10 \\\n",
    "        --results_dir \"./results/expanded_pix_fused\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d5de237-36ff-4fe1-ac99-842158138758",
   "metadata": {},
   "source": [
    "Evaluate the model with **onehot** label:\n",
    "\n",
    "The result doesn't looks good for onehot-labeled input. According to [this comment](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/issues/575#issuecomment-476904244), the author of pix2pix pointed out that the input encoding are treated as RGB images, thus won't work well with too many categories. He further said that in pix2pixHD and SPADE, the input map are treated as one-hot label map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0294533f-d8d4-447d-9511-023fb35da2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "uop_dataset_dir = C.DATASET_PATTERN.format(data='uop')\n",
    "name = 'onehot_cross_pix'\n",
    "results_dir = \"./results/\" + name\n",
    "for ep in [200]:\n",
    "    !CUDA_VISIBLE_DEVICES=1 python submodules/pix2pix/test.py  \\\n",
    "        --dataroot $uop_dataset_dir \\\n",
    "        --name $name \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB \\\n",
    "        --epoch {ep} \\\n",
    "        --batch_size 10 \\\n",
    "        --results_dir $results_dir \\\n",
    "        --input_nc 7 \\\n",
    "        --output_nc 1 \\\n",
    "        --dataset_mode oct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb26a40-b644-47a1-8066-de052a94846b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d6c494643665efee2861d6c88525132bc20bfded38d54b8f73e835c03ec5c7cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
