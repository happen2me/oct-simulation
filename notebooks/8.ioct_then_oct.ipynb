{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "719423eb-422b-4602-a37b-940f72b10eee",
   "metadata": {},
   "source": [
    "# iOCT then OCT\n",
    "\n",
    "In this notebook, I first train a pix2pix model on the iOCT domain. Then I finetune it on the OCT domain to gain better quality layers.\n",
    "\n",
    "TODOs:\n",
    "- Get a unified-labeled iOCT dataset\n",
    "- Get a unified-labeled OCT dataset\n",
    "- (Optional) Add a segmentation label of *shadow*\n",
    "- Train Pix2pix on the iOCT\n",
    "- Finetune the pix2pix on OCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e083c-5aa5-421c-b3fc-f2036a28377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/extra/micheal/IDP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b8659a-24fb-4a11-a480-949a18b6817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, basename\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d568991a-d2b8-4710-9030-67ad89e95508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import idp_utils.data_handling.constants as C\n",
    "from idp_utils.data_handling.ulabel import load_as_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f381daf-c38a-445d-b044-48edfa5a77c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 1. Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32127e11-8e9b-4b1a-9aef-3f78e44fb83c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1. Unify aroi labels\n",
    "\n",
    "Load labels in `split/aroi` dataset, unify the layer labels and remove the fluids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a29ad24-3124-4bb6-8d6e-e57818f98a35",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Unify and copy labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceeb03f-811c-4455-8f44-3e4b713086be",
   "metadata": {},
   "outputs": [],
   "source": [
    "aroi_root = C.SPLIT_PATTERN.format(data='aroi')\n",
    "unified_aroi_root = C.SPLIT_PATTERN.format(data='uaroi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc8446d-cae0-45e5-8d1f-5e9936e9c7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = aroi_root + \"labels/test/patient10_raw0043.png\"\n",
    "arr = load_as_array(path, label_type='aroi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9212b02-cd8a-4c62-9049-f5747fc66e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_labels(src_root, dst_root, img_types, splits, label_type, save_extension=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    img_types: ['bscans', 'labels']\n",
    "    splits: ['train', 'val', 'test']\n",
    "    save_extension: if left None, the extension will be left untouched\n",
    "    \"\"\"\n",
    "    for typ in img_types:\n",
    "        for split in splits:\n",
    "            data_dir = join(src_root, typ, split)\n",
    "            dst_dir = join(dst_root, typ, split)\n",
    "            Path(dst_dir).mkdir(parents=True, exist_ok=True)\n",
    "            img_paths = glob(join(data_dir, '*'))\n",
    "            for img_path in tqdm(img_paths, desc=typ + ' ' + split):\n",
    "                img_name = basename(img_path)\n",
    "                if save_extension is not None:\n",
    "                    # Remove original extension and append new one\n",
    "                    img_name = '.'.join(img_name.split('.')[:-1] + [save_extension])\n",
    "                arg_label_type = label_type if typ == 'labels' else None\n",
    "                img_array = load_as_array(img_path, label_type=arg_label_type)\n",
    "                img_processed = Image.fromarray(img_array)\n",
    "                img_processed.save(join(dst_dir, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde477dc-700b-4d10-bf04-8e073af8d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_labels(src_root=aroi_root,\n",
    "                dst_root=unified_aroi_root,\n",
    "                img_types=['labels'],\n",
    "                splits=['train', 'val', 'test'],\n",
    "                label_type='aroi',\n",
    "                save_extension='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa32394-053c-4632-b15e-f222080029ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Hard link bscans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3e435e-8d01-4bbc-bf9d-22a1961195c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf $unified_aroi_root/bscans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173af7b1-0a82-44d2-83f6-1278526153bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -lR $aroi_root/bscans $unified_aroi_root/bscans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9acfcd-133e-4bbd-bda4-e56a81c9c8ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2. Unify OP (iOCT) labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479728ee-0ded-43cd-abaf-a5b3498942d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_root = C.SPLIT_PATTERN.format(data='ioct')\n",
    "unified_op_root = C.SPLIT_PATTERN.format(data='uop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331be069-10df-4d83-829d-441aaff86c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unify labels\n",
    "transform_labels(src_root=op_root,\n",
    "                dst_root=unified_op_root,\n",
    "                img_types=['labels'],\n",
    "                splits=['train', 'val', 'test'],\n",
    "                label_type='op',\n",
    "                save_extension='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5427e33-c149-4bee-8fef-58b3c5600015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard link bscans\n",
    "# !cp -lR $op_root/bscans $unified_op_root/bscans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c40596-c3a1-47ca-836d-c5d2d516afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify success\n",
    "!ls $op_root/bscans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20916da4-b8ce-484f-a030-c42f886a2955",
   "metadata": {},
   "source": [
    "### 3. Create iOCT(op) and OCT(aroi) datasets\n",
    "\n",
    "`python datasets/combine_A_and_B.py --fold_A /path/to/data/A --fold_B /path/to/data/B --fold_AB /path/to/data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d853c76-2179-4b62-83d9-73ef5f5e1cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "uaroi_dataset_dir = C.DATASET_PATTERN.format(data='uaroi')\n",
    "uop_dataset_dir = C.DATASET_PATTERN.format(data='uop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95166c92-ce82-478a-8e8f-6b072b934263",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $uop_dataset_dir $uaroi_dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa780dcd-c597-4d47-bba3-cb0dc6186a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "aroi_label_dir = join(aroi_root, 'labels')\n",
    "aroi_bscan_dir = join(aroi_root, 'bscans')\n",
    "op_label_dir = join(op_root, 'labels')\n",
    "op_bscan_dir = join(op_root, 'bscans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2292afa3-c4fc-4985-9b97-837a5a0d69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare unified AROI dataset\n",
    "!python pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py \\\n",
    "    --fold_A $aroi_label_dir \\\n",
    "    --fold_B $aroi_bscan_dir \\\n",
    "    --fold_AB $uaroi_dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca46f06-eb70-467f-99f5-c9a7e8bb48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare unified OP dataset\n",
    "!python pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py \\\n",
    "    --fold_A $op_label_dir \\\n",
    "    --fold_B $op_bscan_dir \\\n",
    "    --fold_AB $uop_dataset_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f618fdb4-c340-4f14-ab1d-fbe7137f55d3",
   "metadata": {},
   "source": [
    "## Part 2. Train a pix2pix on iOCT first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad2a8f-5f42-4370-b7f9-9f93b986f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python pytorch-CycleGAN-and-pix2pix/train.py --dataroot $uop_dataset_dir \\\n",
    "    --name \"uop_pix\" \\\n",
    "    --direction AtoB \\\n",
    "    --n_epochs 100 \\\n",
    "    --print_freq 500 \\\n",
    "    --batch_size 64 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef11c071-fc2d-4314-b036-dc4303ee076a",
   "metadata": {},
   "source": [
    "Find the location of the artifacts: model weight path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209bf6a-7e35-405f-9c7f-ac4b12f06c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34119313-7fcf-4d57-b03c-03eda2fb71c1",
   "metadata": {},
   "source": [
    "## Part 3. Fine tune on the OCT dataset\n",
    "\n",
    "TODOs:\n",
    "1. load weight of the pix2pix trained on the iOCT dataset\n",
    "2. train the pix2pix on the OCT dataset, but with smaller epoch\n",
    "\n",
    "Finetune tips: [link](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/tips.md#fine-tuningresume-training)\n",
    "\n",
    "To fine-tune a pre-trained model, or resume the previous training, use the `--continue_train` flag. The program will then load the model based on `epoch`. By default, the program will initialize the epoch count as 1. Set `--epoch_count <int>` to specify a different starting epoch count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed702a96-aa0a-4fa3-87eb-e3d5b6026fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python pytorch-CycleGAN-and-pix2pix/train.py --dataroot $uaroi_dataset_dir \\\n",
    "    --name \"uop_pix\" \\\n",
    "    --direction AtoB \\\n",
    "    --n_epochs 110 \\\n",
    "    --print_freq 500 \\\n",
    "    --batch_size 64 \\\n",
    "    --continue_train \\\n",
    "    --epoch_count 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
