{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTnncJmxffgl"
   },
   "source": [
    "We first mount our Google Drive. The repository of [pytorch-CycleGAN-and-pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/) is already cloned under IDP folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import idp_utils.data_handling.constants as C\n",
    "\n",
    "%cd $C.ROOT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wNjDKdQy35h"
   },
   "source": [
    "# 1 Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbFhP-3ifh6t"
   },
   "source": [
    "Install dependencies of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3688,
     "status": "ok",
     "timestamp": 1649284582498,
     "user": {
      "displayName": "QIANYUN LI",
      "userId": "07764411403341206285"
     },
     "user_tz": -120
    },
    "id": "Pt3igws3eiVp",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "6992a7ac-4362-48ae-96e5-351fcc0d50b3"
   },
   "outputs": [],
   "source": [
    "!cd pytorch-CycleGAN-and-pix2pix && pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdUz4116xhpm"
   },
   "source": [
    "# 2 Pretrained models\n",
    "\n",
    "Download one of the official pretrained models with:\n",
    "\n",
    "-   `bash ./scripts/download_pix2pix_model.sh [edges2shoes, sat2map, map2sat, facades_label2photo, and day2night]`\n",
    "\n",
    "Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9467,
     "status": "ok",
     "timestamp": 1648545458937,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "GC2DEP4M0OsS",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "4777ed5c-cd90-4af2-e119-7d9c30f93517",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!bash pytorch-CycleGAN-and-pix2pix/scripts/download_pix2pix_model.sh edges2shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFw1kDQBx3LN"
   },
   "source": [
    "# 3 Training\n",
    "\n",
    "-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n",
    "\n",
    "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, use the following command to spin up a Visdom server. Enter [localhost:8097](localhost:8097) to accesss visdom page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# !python -m visdom.server -p 8097 > log/visdom.log 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeOLWI8JLMCx",
    "tags": []
   },
   "source": [
    "## 3.1 Train with Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1.1 AROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='AROI', name='original')\n",
    "checkpoint_name = 'pix2pix_aroi_original'\n",
    "n_epochs = 100\n",
    "print_freq = 500\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python pytorch-CycleGAN-and-pix2pix/train.py \n",
    "        --gpu_ids 0\n",
    "        --dataroot $dataset_folder \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB \\\n",
    "        --n_epochs $n_epochs \\\n",
    "        --print_freq $print_freq \\\n",
    "        --batch_size $batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "python pytorch-CycleGAN-and-pix2pix/train.py \\\n",
    "        --gpu_ids 1 \\\n",
    "        --dataroot 'data/datasets/AROI/original' \\\n",
    "        --name 'pix2pix_aroi_original' \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB \\\n",
    "        --n_epochs 100 \\\n",
    "        --print_freq 500 \\\n",
    "        --batch_size 64 \\\n",
    "        > train_pix2pix_aroi_original.log 2>&1 &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.1.2 OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='OP', name='original')\n",
    "checkpoint_name = 'pix2pix_op_original'\n",
    "n_epochs = 100\n",
    "print_freq = 500\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!python pytorch-CycleGAN-and-pix2pix/train.py \\\n",
    "        --gpu_ids 0 \\\n",
    "        --dataroot $dataset_folder \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB \\\n",
    "        --n_epochs $n_epochs \\\n",
    "        --print_freq $print_freq \\\n",
    "        --batch_size $batch_size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.2 Train with Reduced-layer & Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UkcaFZiyASl",
    "tags": []
   },
   "source": [
    "# 4 Testing\n",
    "\n",
    "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
    "\n",
    "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
    "\n",
    "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
    "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
    "\n",
    "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
    "\n",
    "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYMKvV9an0qF",
    "tags": []
   },
   "source": [
    "## 4.1 Test with Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 4.1.1 AROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='AROI', name='original')\n",
    "dataset_test_folder = os.path.join(dataset_folder, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!echo $(ls -l $dataset_test_folder |  egrep -c '^-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!NUM_TEST_AROI=$(ls -l $dataset_test_folder |  egrep -c '^-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='AROI', name='original')\n",
    "checkpoint_name = 'pix2pix_aroi_original'\n",
    "\n",
    "!python pytorch-CycleGAN-and-pix2pix/test.py \\\n",
    "        --dataroot $dataset_folder \\\n",
    "        --direction AtoB \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --num_test 377"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='OP', name='original')\n",
    "dataset_test_folder = os.path.join(dataset_folder, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "! ls -l $dataset_test_folder | egrep -c '^-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='OP', name='original')\n",
    "checkpoint_name = 'pix2pix_op_original'\n",
    "\n",
    "!python pytorch-CycleGAN-and-pix2pix/test.py \\\n",
    "        --dataroot $dataset_folder \\\n",
    "        --direction AtoB \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --num_test 5355"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "7wNjDKdQy35h",
    "8daqlgVhw29P",
    "gdUz4116xhpm",
    "yFw1kDQBx3LN",
    "SeOLWI8JLMCx",
    "DRg8N8sgLTHb",
    "f-acVMQSNL35",
    "i9OCNkaopwAH",
    "xoNWP65aojhI",
    "m1sLooxGom2W"
   ],
   "machine_shape": "hm",
   "name": "pix2pix",
   "provenance": [
    {
     "file_id": "https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb",
     "timestamp": 1648032040861
    }
   ]
  },
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "interpreter": {
   "hash": "341eb00c4a9278ff831ee92c03245caab542deedbe9556143b586a9f4837c15e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
