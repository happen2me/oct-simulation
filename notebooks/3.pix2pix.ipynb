{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTnncJmxffgl"
   },
   "source": [
    "We first mount our Google Drive. The repository of [pytorch-CycleGAN-and-pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/) is already cloned under IDP folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: root path is at oct, expect IDP\n",
      "/mnt/data/shen/archive/oct\n"
     ]
    }
   ],
   "source": [
    "import idp_utils.data_handling.constants as C\n",
    "\n",
    "%cd $C.ROOT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wNjDKdQy35h"
   },
   "source": [
    "# 1 Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbFhP-3ifh6t"
   },
   "source": [
    "Install dependencies of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3688,
     "status": "ok",
     "timestamp": 1649284582498,
     "user": {
      "displayName": "QIANYUN LI",
      "userId": "07764411403341206285"
     },
     "user_tz": -120
    },
    "id": "Pt3igws3eiVp",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "6992a7ac-4362-48ae-96e5-351fcc0d50b3"
   },
   "outputs": [],
   "source": [
    "!cd submodules/pix2pix && pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdUz4116xhpm"
   },
   "source": [
    "# 2 Pretrained models\n",
    "\n",
    "Download one of the official pretrained models with:\n",
    "\n",
    "-   `bash ./scripts/download_pix2pix_model.sh [edges2shoes, sat2map, map2sat, facades_label2photo, and day2night]`\n",
    "\n",
    "Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9467,
     "status": "ok",
     "timestamp": 1648545458937,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "GC2DEP4M0OsS",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "4777ed5c-cd90-4af2-e119-7d9c30f93517",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: available models are edges2shoes, sat2map, map2sat, facades_label2photo, and day2night\n",
      "Specified [edges2shoes]\n",
      "WARNING: timestamping does nothing in combination with -O. See the manual\n",
      "for details.\n",
      "\n",
      "--2023-03-15 16:48:24--  http://efrosgans.eecs.berkeley.edu/pix2pix/models-pytorch/edges2shoes.pth\n",
      "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\n",
      "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 217704688 (208M)\n",
      "Saving to: ‘./checkpoints/edges2shoes_pretrained/latest_net_G.pth’\n",
      "\n",
      "./checkpoints/edges 100%[===================>] 207,62M  17,2MB/s    in 13s     \n",
      "\n",
      "2023-03-15 16:48:38 (15,4 MB/s) - ‘./checkpoints/edges2shoes_pretrained/latest_net_G.pth’ saved [217704688/217704688]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash submodules/pix2pix/scripts/download_pix2pix_model.sh edges2shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFw1kDQBx3LN"
   },
   "source": [
    "# 3 Training\n",
    "\n",
    "-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n",
    "\n",
    "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, use the following command to spin up a Visdom server. Enter [localhost:8097](localhost:8097) to accesss visdom page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python -m visdom.server -p 8097 > logs/visdom.log 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeOLWI8JLMCx",
    "tags": []
   },
   "source": [
    "## 3.1 Train with Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1.1 AROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='AROI', name='original')\n",
    "checkpoint_name = 'pix2pix_aroi_original'\n",
    "n_epochs = 100\n",
    "print_freq = 500\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python pytorch-CycleGAN-and-pix2pix/train.py \n",
    "        --gpu_ids 0\n",
    "        --dataroot $dataset_folder \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB \\\n",
    "        --n_epochs $n_epochs \\\n",
    "        --print_freq $print_freq \\\n",
    "        --batch_size $batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "python pytorch-CycleGAN-and-pix2pix/train.py \\\n",
    "        --gpu_ids 1 \\\n",
    "        --dataroot 'data/datasets/AROI/original' \\\n",
    "        --name 'pix2pix_aroi_original' \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB \\\n",
    "        --n_epochs 100 \\\n",
    "        --print_freq 500 \\\n",
    "        --batch_size 64 \\\n",
    "        > train_pix2pix_aroi_original.log 2>&1 &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.1.2 OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='OP', name='original')\n",
    "checkpoint_name = 'pix2pix_op_original'\n",
    "n_epochs = 100\n",
    "print_freq = 500\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!python pytorch-CycleGAN-and-pix2pix/train.py \\\n",
    "        --gpu_ids 0 \\\n",
    "        --dataroot $dataset_folder \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB \\\n",
    "        --n_epochs $n_epochs \\\n",
    "        --print_freq $print_freq \\\n",
    "        --batch_size $batch_size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.2 Train with Reduced-layer & Original Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Train with Mixed-domain Data, Diff Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='OPAROI_DIFF', name='original')\n",
    "checkpoint_name = 'pix2pix_oparoi_diff'\n",
    "n_epochs = 100\n",
    "print_freq = 500\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/datasets/OPAROI_DIFF'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -W ignore submodules/pix2pix/train.py \\\n",
    "        --gpu_ids 0 \\\n",
    "        --dataroot $dataset_folder \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB \\\n",
    "        --n_epochs $n_epochs \\\n",
    "        --print_freq $print_freq \\\n",
    "        --batch_size $batch_size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UkcaFZiyASl",
    "tags": []
   },
   "source": [
    "# 4 Testing\n",
    "\n",
    "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
    "\n",
    "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
    "\n",
    "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
    "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
    "\n",
    "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
    "\n",
    "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYMKvV9an0qF",
    "tags": []
   },
   "source": [
    "## 4.1 Test with Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 4.1.1 AROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='AROI', name='original')\n",
    "dataset_test_folder = os.path.join(dataset_folder, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!echo $(ls -l $dataset_test_folder |  egrep -c '^-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!NUM_TEST_AROI=$(ls -l $dataset_test_folder |  egrep -c '^-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='AROI', name='original')\n",
    "checkpoint_name = 'pix2pix_aroi_original'\n",
    "\n",
    "!python pytorch-CycleGAN-and-pix2pix/test.py \\\n",
    "        --dataroot $dataset_folder \\\n",
    "        --direction AtoB \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --num_test 377"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='OP', name='original')\n",
    "dataset_test_folder = os.path.join(dataset_folder, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "! ls -l $dataset_test_folder | egrep -c '^-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='OP', name='original')\n",
    "checkpoint_name = 'pix2pix_op_original'\n",
    "\n",
    "!python pytorch-CycleGAN-and-pix2pix/test.py \\\n",
    "        --dataroot $dataset_folder \\\n",
    "        --direction AtoB \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --num_test 5355"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "7wNjDKdQy35h",
    "8daqlgVhw29P",
    "gdUz4116xhpm",
    "yFw1kDQBx3LN",
    "SeOLWI8JLMCx",
    "DRg8N8sgLTHb",
    "f-acVMQSNL35",
    "i9OCNkaopwAH",
    "xoNWP65aojhI",
    "m1sLooxGom2W"
   ],
   "machine_shape": "hm",
   "name": "pix2pix",
   "provenance": [
    {
     "file_id": "https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb",
     "timestamp": 1648032040861
    }
   ]
  },
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "interpreter": {
   "hash": "341eb00c4a9278ff831ee92c03245caab542deedbe9556143b586a9f4837c15e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
