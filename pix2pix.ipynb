{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTnncJmxffgl"
   },
   "source": [
    "We first mount our Google Drive. The repository of [pytorch-CycleGAN-and-pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/) is already cloned under IDP folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.constants as C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wNjDKdQy35h"
   },
   "source": [
    "# 1 Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbFhP-3ifh6t"
   },
   "source": [
    "Install dependencies of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3688,
     "status": "ok",
     "timestamp": 1649284582498,
     "user": {
      "displayName": "QIANYUN LI",
      "userId": "07764411403341206285"
     },
     "user_tz": -120
    },
    "id": "Pt3igws3eiVp",
    "outputId": "6992a7ac-4362-48ae-96e5-351fcc0d50b3"
   },
   "outputs": [],
   "source": [
    "!cd pytorch-CycleGAN-and-pix2pix && pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8daqlgVhw29P",
    "tags": []
   },
   "source": [
    "# 2 Datasets\n",
    "\n",
    "We use our own dataset created following this [guide](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/datasets.md#pix2pix-datasets). It is located at `data/datasets/[datasetname]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZF52TjFV6Cu4"
   },
   "source": [
    "the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 334,
     "status": "ok",
     "timestamp": 1649281197768,
     "user": {
      "displayName": "QIANYUN LI",
      "userId": "07764411403341206285"
     },
     "user_tz": -120
    },
    "id": "Dn1vJ46TG3-1",
    "outputId": "a4c16916-88c3-4097-f7f1-189752ff7731"
   },
   "outputs": [],
   "source": [
    "!ls data/datasets/AROI/reduce1_merge_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdUz4116xhpm"
   },
   "source": [
    "# 3 Pretrained models\n",
    "\n",
    "Download one of the official pretrained models with:\n",
    "\n",
    "-   `bash ./scripts/download_pix2pix_model.sh [edges2shoes, sat2map, map2sat, facades_label2photo, and day2night]`\n",
    "\n",
    "Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9467,
     "status": "ok",
     "timestamp": 1648545458937,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "GC2DEP4M0OsS",
    "outputId": "4777ed5c-cd90-4af2-e119-7d9c30f93517"
   },
   "outputs": [],
   "source": [
    "!bash pytorch-CycleGAN-and-pix2pix/scripts/download_pix2pix_model.sh edges2shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFw1kDQBx3LN"
   },
   "source": [
    "# 4 Training\n",
    "\n",
    "-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n",
    "\n",
    "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants as C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, use the following command to spin up a Visdom server. Enter [localhost:8097](localhost:8097) to accesss visdom page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/home/extra/micheal/IDP/miniconda3/bin/python -m visdom.server -p 8097 &>/dev/null &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeOLWI8JLMCx",
    "tags": []
   },
   "source": [
    "## 4.1 Train with Original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 RTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='DME', name='original')\n",
    "checkpoint_name = 'dme_original_pix2pix'\n",
    "\n",
    "!python pytorch-CycleGAN-and-pix2pix/train.py \\\n",
    "        --dataroot $dataset_folder \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 DME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='DME', name='original')\n",
    "checkpoint_name = 'dme_original_pix2pix'\n",
    "\n",
    "!python pytorch-CycleGAN-and-pix2pix/train.py \\\n",
    "        --dataroot $dataset_folder \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.1.3 AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='AMD', name='original')\n",
    "checkpoint_name = 'amd_original_pix2pix'\n",
    "\n",
    "!python pytorch-CycleGAN-and-pix2pix/train.py \\\n",
    "        --dataroot $dataset_folder \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB \\\n",
    "        --n_epochs 100 \\\n",
    "        --print_freq 500 \\\n",
    "        --batch_size 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python pytorch-CycleGAN-and-pix2pix/train.py --dataroot ./data/datasets/OP/original --name op_original_pix2pix --model pix2pix --direction AtoB --n_epochs 100 --print_freq 500 --batch_size 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='OP', name='original')\n",
    "checkpoint_name = 'op_original_pix2pix'\n",
    "\n",
    "!NVIDIA_VISIBLE_DEVICES=1 python pytorch-CycleGAN-and-pix2pix/train.py \\\n",
    "        --dataroot $dataset_folder \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB \\\n",
    "        --n_epochs 100 \\\n",
    "        --print_freq 500 \\\n",
    "        --batch_size 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRg8N8sgLTHb"
   },
   "source": [
    "## 4.2 Train with Combined Data (Original Data + Layer-reduced Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 RTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='RTA', name='reduce_merge')\n",
    "checkpoint_name = 'rta_reduce_merge_pix2pix'\n",
    "\n",
    "!python pytorch-CycleGAN-and-pix2pix/train.py \\\n",
    "        --dataroot $dataset_folder \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2.2 DME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='DME', name='reduce_merge')\n",
    "checkpoint_name = 'dme_reduce_merge_pix2pix'\n",
    "\n",
    "!python pytorch-CycleGAN-and-pix2pix/train.py \\\n",
    "        --dataroot $dataset_folder \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2.3 AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='AMD', name='reduce_merge')\n",
    "checkpoint_name = 'amd_reduce_merge_pix2pix'\n",
    "\n",
    "!python pytorch-CycleGAN-and-pix2pix/train.py \\\n",
    "        --dataroot $dataset_folder \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2.4 AROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1649277662427,
     "user": {
      "displayName": "QIANYUN LI",
      "userId": "07764411403341206285"
     },
     "user_tz": -120
    },
    "id": "y9rto6cdLaVz",
    "outputId": "709fe247-637f-4f27-c518-b209b8653af2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='AROI', name='reduce1_merge')\n",
    "checkpoint_name = 'aroi_reduce_merge_pix2pix'\n",
    "\n",
    "!python pytorch-CycleGAN-and-pix2pix/train.py \\\n",
    "        --dataroot $dataset_folder \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --direction AtoB \\\n",
    "        --n_epochs 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UkcaFZiyASl",
    "tags": []
   },
   "source": [
    "# 5 Testing\n",
    "\n",
    "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
    "\n",
    "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
    "\n",
    "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
    "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
    "\n",
    "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
    "\n",
    "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYMKvV9an0qF",
    "tags": []
   },
   "source": [
    "## 5.1 Test with Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 5.1.3 AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='AMD', name='original')\n",
    "checkpoint_name = 'amd_original_pix2pix'\n",
    "\n",
    "!python pytorch-CycleGAN-and-pix2pix/test.py \\\n",
    "        --dataroot $dataset_folder \\\n",
    "        --direction AtoB \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --num_test 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-acVMQSNL35",
    "tags": []
   },
   "source": [
    "## 5.2 Test with Combined Data (Original Data + Layer-reduced Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 5.1.2 DME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset_folder = C.DATASET_PATTERN.format(data='DME', name='reduce_merge')\n",
    "checkpoint_name = 'dme_reduce_merge_pix2pix'\n",
    "\n",
    "!python pytorch-CycleGAN-and-pix2pix/test.py \\\n",
    "        --dataroot $dataset_folder \\\n",
    "        --direction AtoB \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --num_test 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.1.4 AROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12013,
     "status": "ok",
     "timestamp": 1649251156710,
     "user": {
      "displayName": "QIANYUN LI",
      "userId": "07764411403341206285"
     },
     "user_tz": -120
    },
    "id": "KViHxZ5MNWva",
    "outputId": "a1f7b27f-4735-4a8d-de4a-49528e9d3afe"
   },
   "outputs": [],
   "source": [
    "dataset_folder = C.DATASET_PATTERN.format(data='AROI', name='reduce1_merge')\n",
    "checkpoint_name = 'aroi_reduce_merge_pix2pix'\n",
    "\n",
    "!python pytorch-CycleGAN-and-pix2pix/test.py \\\n",
    "        --dataroot $dataset_folder \\\n",
    "        --direction AtoB \\\n",
    "        --name $checkpoint_name \\\n",
    "        --model pix2pix \\\n",
    "        --num_test 400"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "7wNjDKdQy35h",
    "8daqlgVhw29P",
    "gdUz4116xhpm",
    "yFw1kDQBx3LN",
    "SeOLWI8JLMCx",
    "DRg8N8sgLTHb",
    "f-acVMQSNL35",
    "i9OCNkaopwAH",
    "xoNWP65aojhI",
    "m1sLooxGom2W"
   ],
   "machine_shape": "hm",
   "name": "pix2pix",
   "provenance": [
    {
     "file_id": "https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb",
     "timestamp": 1648032040861
    }
   ]
  },
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "interpreter": {
   "hash": "341eb00c4a9278ff831ee92c03245caab542deedbe9556143b586a9f4837c15e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
