{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1688,
     "status": "ok",
     "timestamp": 1649275852033,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "t_i1NGq_JLZy"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "from glob import glob\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io\n",
    "import imageio\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9FZFX3ILJYb"
   },
   "source": [
    "# 1 Constant Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2l3zVo-LVRO",
    "tags": []
   },
   "source": [
    "## 1.1 Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1649275855879,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "RALKync3Wwh6"
   },
   "outputs": [],
   "source": [
    "import utils.constants as C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1649275861005,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "pg1fYY6OJP_4"
   },
   "outputs": [],
   "source": [
    "seed = 6\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-Kilc7tLg6u",
    "tags": []
   },
   "source": [
    "## 1.2 Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcO_fZ3XLpJD"
   },
   "source": [
    "![DME Layers](https://opg.optica.org/getImage.cfm?img=M3cuZnVsbCxib2UtNi00LTExNzItZzAwMw&article=boe-6-4-1172-g003)\n",
    "\n",
    "-----\n",
    "\n",
    "![RTA Layers Image](https://journals.plos.org/plosone/article/figure/image?size=large&id=10.1371/journal.pone.0133908.g001) | ![RTA Layers Explanation](https://journals.plos.org/plosone/article/figure/image?size=large&id=10.1371/journal.pone.0133908.t001)\n",
    "-- | --\n",
    "\n",
    "![AMD Layers](https://www.ncbi.nlm.nih.gov/pmc/articles/instance/3901571/bin/nihms-508161-f0001.jpg)\n",
    "\n",
    "----\n",
    "\n",
    "![AROI Layers](https://ipg.fer.hr/images/50037599/nasa%20baza.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1649275868442,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "TrIN18nHLojz",
    "outputId": "67a2e3df-fbfb-4d86-8328-56c7a86a40f4"
   },
   "outputs": [],
   "source": [
    "num_gap = 12 + 1\n",
    "gap = 255 // num_gap\n",
    "\n",
    "ILM = 1 * gap # present in 1, 2, 3, 4\n",
    "RNFL_o = 2 * gap # NFL/FCL in DME, present in 2\n",
    "IPL_INL = 3 * gap\n",
    "INL_OPL = 4 * gap\n",
    "OPL_o = 5 * gap # OPL/ONL in DME\n",
    "ISM_ISE = 6 * gap\n",
    "IS_OS = 7 * gap\n",
    "OS_RPE = 8 * gap\n",
    "\n",
    "# not sure whether they are the same\n",
    "RPE = 9 * gap\n",
    "# RPEDC = 10 * gap\n",
    "# RPE = 11 * gap\n",
    "\n",
    "BM = 10 * gap\n",
    "print(0, ILM, RNFL_o, IPL_INL, INL_OPL, OPL_o, ISM_ISE, IS_OS, OS_RPE, RPE, BM, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1649275869287,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "YRYmYG_-Lw73"
   },
   "outputs": [],
   "source": [
    "RTA_LABELS = [ILM, RNFL_o, IPL_INL, INL_OPL, OPL_o, IS_OS, OS_RPE, RPE]\n",
    "DME_LABELS = [ILM, RNFL_o, IPL_INL, INL_OPL, OPL_o, ISM_ISE, OS_RPE, BM]\n",
    "AMD_LABELS = [ILM, RPE, BM]\n",
    "AROI_LABELS = [ILM, IPL_INL, RPE, BM]\n",
    "OP_LABELS = [ILM, RPE]\n",
    "FLUID_LABELS = [80, 160, 240]\n",
    "INSTRUMENT_LABELS = [100, 200] # 100 for real instrument, 200 for reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzl7iUiIMBTi"
   },
   "source": [
    "# 2 Extract Labeled Layeres & Bscans from Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZh3WsSnQEQc",
    "tags": []
   },
   "source": [
    "## 2.1 Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1649275877873,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "MYjqY4M6OIBA"
   },
   "outputs": [],
   "source": [
    "def get_dme_valid_idx(patient, key='manualLayers1'):\n",
    "    valid_idx = []\n",
    "    for i in range(patient[key].shape[-1]):\n",
    "        x = np.max(np.asarray(np.nan_to_num(patient[key][:,:,i])))\n",
    "        if x > 0:\n",
    "            valid_idx.append(i)\n",
    "    return valid_idx\n",
    "\n",
    "def get_amd_valid_idx(patient, key='layerMaps'):\n",
    "    '''\n",
    "    The 11 B-scans per patient were annotated centered at fovea and 5 frames on either side of the fovea\n",
    "    This function gives the valid B-scans index\n",
    "    '''\n",
    "    idx = []\n",
    "    for i in range(patient[key].shape[0]):\n",
    "        x = patient[key][i,:,:]\n",
    "        if np.sum(np.nan_to_num(x)) != 0:\n",
    "            idx.append(i)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1649275878110,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "QQk4zt3jOlj_"
   },
   "outputs": [],
   "source": [
    "def detect_edges(img):\n",
    "    '''\n",
    "    Detect edges vertically for AROI colormap. It returns edges in the shape of (width, #edges)\n",
    "    '''\n",
    "    shape = img.shape\n",
    "    num_edge = 4\n",
    "    edges = np.zeros((shape[1], num_edge), dtype=int)\n",
    "    for i in range(shape[1]):\n",
    "        for j in range(1, num_edge+1):\n",
    "            # get the upper bound of class j\n",
    "            idx = np.nonzero(img[:, i] == j)[0][0]\n",
    "            # if fluids on boundary, get the lower bound of class j-1\n",
    "            if idx - edges[i-1][j-1] > 15:\n",
    "                idx = np.nonzero(img[:, i] == j-1)[0][-1]\n",
    "            edges[i][j-1] = idx\n",
    "    return edges\n",
    "\n",
    "def detect_fluids(img, intensities):\n",
    "    '''\n",
    "    Detect fluids for AROI colormap. It returns edges in the shape of img\n",
    "    '''\n",
    "    labels = [5, 6, 7]\n",
    "    fluids = np.zeros_like(img)\n",
    "    for idx, label in enumerate(labels):\n",
    "        coor_tuples = np.where(img == label)\n",
    "        if coor_tuples[0].size != 0:\n",
    "            intensity = intensities[idx]\n",
    "            coors = zip(coor_tuples[0], coor_tuples[1])\n",
    "            for coor in coors:\n",
    "                fluids[coor[0]][coor[1]] = intensity\n",
    "    return fluids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1649275878336,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "EtssSVBjMcef"
   },
   "outputs": [],
   "source": [
    "def extract_data(file_pattern, bscan_key, layermap_key, bscan_format, layermap_format, layer_labels, bscan_folder, layer_folder, \n",
    "                       fluid_folder=None, fluid_key=None, valid_slice_indices_fn=None, remove_from=None, n_remove=0, overwrite=True):\n",
    "    '''\n",
    "    Extract bscan, corresponding layer images and fluid (if exists) from mat files. Extracted bscans, layers and fluids\n",
    "    will be saved as .jpg images to specified bscan and layer folders with the original file name.\n",
    "    If remove_from is specified, n_remove layers randomly sampled from remove_from list will be removed.\n",
    "    Args:\n",
    "      file_pattern (str): a pattern leads to mat files, which contains bscans and layermaps, i.e. /path/to/mat/patient*.mat\n",
    "      bscan_key (str): the retrieval key of the bscan in the mat\n",
    "      layermap_key (str): the retrieval key of the layermap in the mat\n",
    "      bscan_format (str): a combination of h(height), w(width), s(slice); their location corresponds to the shape of bscan file, i.e. 'hws'\n",
    "      layermap_format (str): a combination of w, s, l(layer)\n",
    "      layer_labels (list(int)): the values to assigned to each layer\n",
    "      bscan_folder (str): the folder to save bscan slice images\n",
    "      layer_folder (str): the folder to save layer slice images\n",
    "      fluid_folder (str): the folder to save fluid slice images\n",
    "      valid_slice_indices_fn (function): a function to find valid slice indices in a mat\n",
    "      remove_from (list(int)): a list of layers that can be removed\n",
    "      n_remove (int): number of layers to remove. It should be smaller than the length of remove_from list\n",
    "      overwrite (bool): overwrite existing files.\n",
    "    '''\n",
    "    # Create folders for bscan, layer, and fluid\n",
    "    if not Path(bscan_folder).exists():\n",
    "        Path(bscan_folder).mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"Created bscan folder {bscan_folder}\")\n",
    "    if not Path(layer_folder).exists():\n",
    "        Path(layer_folder).mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"Created layer folder {layer_folder}\")\n",
    "    if fluid_key is not None and fluid_folder is not None and not Path(fluid_folder).exists():\n",
    "        Path(fluid_folder).mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"Created fluid folder {layer_folder}\")\n",
    "    \n",
    "    file_glob = glob(file_pattern)\n",
    "    print(f\"{len(file_glob)} files matches pattern: {file_pattern}\")\n",
    "\n",
    "    # Traverse through each file that matches the given file_pattern\n",
    "    for f in tqdm(file_glob):\n",
    "        mat = scipy.io.loadmat(f)\n",
    "        # Load raw bscan, unplotted layermap and fluid from mat file\n",
    "        bscan = np.asarray(mat[bscan_key])\n",
    "        layermap = np.asarray(np.nan_to_num(mat[layermap_key]), dtype=int)\n",
    "        fluid = None\n",
    "        if fluid_key is not None:\n",
    "            fluid = np.asarray(mat[fluid_key], dtype='uint8')\n",
    "            assert fluid.shape == bscan.shape, f\"Fluid should share same width, height, layer format & shape with bscans {bscan.shape}, but got {fluid.shape}\"\n",
    "        \n",
    "        # Load meta infomation of an image\n",
    "        assert len(bscan.shape) == 3 and len(bscan_format) == 3, f\"bscan is expected to be three dim, but get {bscan_format}({len(bscan.shape)})\"\n",
    "        height = bscan.shape[bscan_format.index('h')]\n",
    "        width = bscan.shape[bscan_format.index('w')]\n",
    "        n_slice = bscan.shape[bscan_format.index('s')]\n",
    "        n_layer = layermap.shape[layermap_format.index('l')]\n",
    "        assert len(layer_labels) >= n_layer, f\"layer_labels should have more elements that #layers({n_layer}), but got length {len(layer_labels)}\"\n",
    "        assert 'w' in layermap_format and 's' in layermap_format and 'l' in layermap_format, f\"layermap_format is illegal, got {layermap_format}\"\n",
    "        assert layermap.shape[layermap_format.index('w')] == width, f\"width of bscan ({width}) is inconsistent with that of layermap ({layermap.shape[layermap_format.index('w')]})\"\n",
    "        assert layermap.shape[layermap_format.index('s')] == n_slice, f\"#slice of bscan ({n_slice}) is inconsistent with that of layermap ({layermap.shape[layermap_format.index('s')]})\"\n",
    "        \n",
    "        # For some images, not every slice contains labeled information. This filters out useless slices.\n",
    "        if valid_slice_indices_fn is not None:\n",
    "            valid_slice_indices = valid_slice_indices_fn(mat)\n",
    "        else:\n",
    "            valid_slice_indices = range(n_slice)\n",
    "        \n",
    "        # Traverse through each slice in a mat\n",
    "        for s in valid_slice_indices:\n",
    "            # check existence, this only works when remove_from is None\n",
    "            save_name = f.split('/')[-1].split('.')[0] + '_' + str(s) + '.jpg'\n",
    "            if not overwrite and Path(os.path.join(bscan_folder, save_name)).exists() and Path(os.path.join(layer_folder, save_name)).exists():\n",
    "                continue\n",
    "            # Extract bscan slice directly\n",
    "            if bscan_format.index('s') == 0:\n",
    "                scan_slice = bscan[s, :, :]\n",
    "            elif bscan_format.index('s') == 1:\n",
    "                scan_slice = bscan[:, s, :]\n",
    "            else: # bscan_format.index('s') == 2\n",
    "                scan_slice = bscan[:, :, s]\n",
    "                \n",
    "            # Plot layer slice with stored layer data\n",
    "            layer_slice = np.zeros_like(scan_slice)\n",
    "            # sample layers to remove if remove_from is specified\n",
    "            layers_remove = None\n",
    "            if remove_from is not None:\n",
    "                layers_remove = random.sample(remove_from, n_remove)\n",
    "                layers_remove = sorted(layers_remove)\n",
    "            for l in range(n_layer):\n",
    "                # skip removed layers\n",
    "                if remove_from is not None and l in layers_remove:\n",
    "                    continue\n",
    "                # Programmatically build layermap width indices (this replaces many if clause)\n",
    "                layer_map_width_indice = [0,0,0]\n",
    "                layer_map_width_indice[layermap_format.index('s')] = s\n",
    "                layer_map_width_indice[layermap_format.index('l')] = l\n",
    "                layer_map_width_indice[layermap_format.index('w')] = range(width)\n",
    "                layer_map_width_indice = tuple(layer_map_width_indice)\n",
    "                layer_slice[layermap[layer_map_width_indice], range(width)] = layer_labels[l] # substitute with layer-specific constant\n",
    "            # This restores the zero-th line of each image back to black pixels (it assumes they used to be black pixels)\n",
    "            # P.S. I forgot why I need this line\n",
    "            layer_slice[0, :] = 0\n",
    "            \n",
    "            # Extract fluid slice directly if fluid_key is set (therefore fluid is not None)\n",
    "            fluid_slice = None\n",
    "            if fluid is not None:\n",
    "                # fluid and bscan share the same format, therefore here I use bscan_format for fluid\n",
    "                if bscan_format.index('s') == 0:\n",
    "                    fluid_slice = fluid[s, :, :]\n",
    "                elif bscan_format.index('s') == 1:\n",
    "                    fluid_slice = fluid[:, s, :]\n",
    "                else: # bscan_format.index('s') == 2\n",
    "                    fluid_slice = fluid[:, :, s]\n",
    "            \n",
    "            # Save each slice as a file\n",
    "            scan_slice_img = Image.fromarray(scan_slice)\n",
    "            layer_slice_img = Image.fromarray(layer_slice)\n",
    "            save_name = f.split('/')[-1].split('.')[0] + '_' + str(s) + '.jpg'\n",
    "            # If the layer is reduced, append delxxx to its save name\n",
    "            if remove_from is not None and len(layers_remove) > 0:\n",
    "                save_name = save_name.split('.')[0] + '_del' + ''.join(str(x) for x in layers_remove) + '.jpg'\n",
    "            scan_slice_img.save(os.path.join(bscan_folder, save_name))\n",
    "            layer_slice_img.save(os.path.join(layer_folder, save_name))\n",
    "            if fluid_slice is not None:\n",
    "                fluid_slice_img = Image.fromarray(fluid_slice)\n",
    "                fluid_slice_img.save(os.path.join(fluid_folder, save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_aroi(raw_data_folder, bscan_folder, layer_folder, fluid_folder, dtype, \n",
    "                            fluid_labels, layer_labels, remove_from=None, n_remove=0,\n",
    "                            save_extension='png'):\n",
    "    ''' output: bscans, fluids, layers folders with corresponding files\n",
    "        args:\n",
    "            raw_data_folder: source raw data folder\n",
    "            bscan_folder: destination bscans folder\n",
    "            layer_folder: destination layers folder\n",
    "            fluid_folder: destination fluids folder\n",
    "            dtype: str, name of type of layers\n",
    "            fluid_labels: fluid label intensities as a list\n",
    "            layer_labels: layer label intensities as a list\n",
    "            remove_from (list(int)): a list of layers that can be removed\n",
    "            n_remove (int): number of layers to remove. It should be smaller than the length of remove_from list\n",
    "    '''    \n",
    "    data =  \"AROI\"\n",
    "    raw_path = f\"24 patient/patient*/raw/labeled/*.png\"\n",
    "    mask_path = f\"24 patient/patient*/mask/number/*.png\"\n",
    "    mask_trunk = \"24 patient/patient{patient_number}/mask/number/patient{patient_number}_raw{slice_number}.png\"\n",
    "    name_pattern = re.compile(\"patient([0-9]+)_raw([0-9]+)\\.png\")\n",
    "    skipped_files = 0\n",
    "    \n",
    "    raw_paths = glob(os.path.join(raw_data_folder, raw_path))\n",
    "    assert len(raw_paths) != 0\n",
    "    mask_paths = glob(os.path.join(raw_data_folder, mask_path))\n",
    "    assert len(mask_paths) != 0\n",
    "    \n",
    "    raw_files = [i.split('/')[-1] for i in raw_paths]\n",
    "    mask_files = [i.split('/')[-1] for i in mask_paths]\n",
    "    \n",
    "    if not Path(bscan_folder).exists():\n",
    "        Path(bscan_folder).mkdir(parents=True)\n",
    "        print(f\"Created folder {bscan_folder}\")\n",
    "\n",
    "    if not Path(layer_folder).exists():\n",
    "        Path(layer_folder).mkdir(parents=True)\n",
    "        print(f\"Created folder {layer_folder}\")\n",
    "\n",
    "    if not Path(fluid_folder).exists():\n",
    "        Path(fluid_folder).mkdir(parents=True)\n",
    "        print(f\"Created folder {fluid_folder}\")\n",
    "        \n",
    "    for raw in tqdm(raw_paths):\n",
    "        assert raw.split('/')[-1] in mask_files, f\"raw image {raw} does not correspond to any image in mask files\"\n",
    "\n",
    "        patient_idx, slice_idx = name_pattern.fullmatch(raw.split('/')[-1]).groups(0)\n",
    "        mask = mask_trunk.format(patient_number=patient_idx, slice_number=slice_idx)\n",
    "        mask = os.path.join(raw_data_folder, mask)\n",
    "\n",
    "        try:\n",
    "            raw_img = imageio.imread(raw) # height, width\n",
    "        except Exception as e:\n",
    "            print(f\"[{skipped_files}]Error occurred when opening {raw}\")\n",
    "            print(e)\n",
    "            skipped_files += 1\n",
    "            continue\n",
    "        mask_img = None\n",
    "\n",
    "        try:\n",
    "            mask_img = imageio.imread(mask)\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred when reading mask\", mask)\n",
    "        if mask_img is None:\n",
    "            print(f\"[{skipped_files}]Read mask is none\")\n",
    "            skipped_files += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            edges = detect_edges(mask_img) # width, #layers\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred when detecting edges\", mask)\n",
    "            skipped_files += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            fluid_slice = detect_fluids(mask_img, fluid_labels)\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred when detecting fluids\", mask)\n",
    "            print(e)\n",
    "            continue\n",
    "            \n",
    "        # label map with layers\n",
    "        layers_remove = None\n",
    "        if remove_from is not None:\n",
    "            layers_remove = random.sample(remove_from, n_remove)\n",
    "            layers_remove = sorted(layers_remove)\n",
    "\n",
    "        width, n_layer = edges.shape\n",
    "        layer_slice = np.zeros_like(raw_img)\n",
    "        for l in range(n_layer):\n",
    "            if remove_from is not None and l in layers_remove:\n",
    "                continue\n",
    "            layer_slice[edges[:, l], range(width)] = layer_labels[l] # substitute with layer-specific constant\n",
    "\n",
    "        # Save each slice as a file\n",
    "        save_name = raw.split('/')[-1].split('.')[0] + '.' + save_extension\n",
    "        \n",
    "        scan_slice_img = Image.fromarray(raw_img)\n",
    "        fluid_slice_img = Image.fromarray(fluid_slice)\n",
    "        layer_slice_img = Image.fromarray(layer_slice)\n",
    "        \n",
    "        scan_slice_img.save(os.path.join(bscan_folder, save_name))\n",
    "        fluid_slice_img.save(os.path.join(fluid_folder, save_name))\n",
    "        if remove_from is not None and len(layers_remove) > 0:\n",
    "            save_name = save_name.split('.')[0] + '_del' + ''.join(str(x) for x in layers_remove) + '.jpg'\n",
    "        layer_slice_img.save(os.path.join(layer_folder, save_name))\n",
    "\n",
    "    print(\"Sum of skipped files: \", skipped_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_op(raw_data_folder, bscan_folder, layer_folder, layer_labels, instrument_labels=None, save_extension='png'):\n",
    "\n",
    "    raw_layer_labels = [1, 3]\n",
    "    raw_instrument_labels = [2, 4]\n",
    "\n",
    "    if not Path(bscan_folder).exists():\n",
    "        Path(bscan_folder).mkdir(parents=True)\n",
    "        print(f\"Created folder {bscan_folder}\")\n",
    "\n",
    "    if not Path(layer_folder).exists():\n",
    "        Path(layer_folder).mkdir(parents=True)\n",
    "        print(f\"Created folder {layer_folder}\")\n",
    "\n",
    "    parts = glob(os.path.join(raw_data_folder, \"*\"))\n",
    "    for part in parts:\n",
    "        print(f\"{part.split('/')[-1]} Started\")\n",
    "        folders = glob(os.path.join(part, \"*\"))\n",
    "        for folder in tqdm(folders):\n",
    "            folder_name = folder.split('/')[-1].split('.')[0]\n",
    "            bscans = glob(os.path.join(folder, \"[0-9]*.bmp\"))\n",
    "            layers = glob(os.path.join(folder, \"segmentation\", \"[0-9]*.bmp\"))\n",
    "            assert len(bscans) !=0 and len(layers) != 0 and len(bscans) == len(layers)\n",
    "\n",
    "            for layer in layers:\n",
    "                layer_name = folder_name + \"-\" + layer.split('/')[-1].split('.')[0] + '.' + save_extension\n",
    "                layer_arr = np.asarray(Image.open(layer))\n",
    "                for i in range(2):\n",
    "                    layer_arr[layer_arr == raw_layer_labels[i]] = layer_labels[i]\n",
    "                if instrument_labels:\n",
    "                    assert len(instrument_labels) >= len(raw_instrument_labels), \\\n",
    "                        f\"instrument_labels ({len(instrument_labels)}) is not enough (expect {len(raw_instrument_labels)})\"\n",
    "                    for i in range(2):\n",
    "                        layer_arr[layer_arr == raw_instrument_labels[i]] = INSTRUMENT_LABELS[i]\n",
    "                layer_img = Image.fromarray(layer_arr)\n",
    "                layer_img.save(os.path.join(layer_folder, layer_name))\n",
    "            \n",
    "            for bscan in bscans:\n",
    "                bscan_name = folder_name + \"-\" + bscan.split('/')[-1].split('.')[0] + '.' + save_extension\n",
    "                bscan_arr = np.asarray(Image.open(bscan))\n",
    "                bscan_img = Image.fromarray(bscan_arr)\n",
    "                bscan_img.save(os.path.join(bscan_folder, bscan_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9vY0A8DM-2P",
    "tags": []
   },
   "source": [
    "## 2.2 Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9PaKEHPNPFu",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2.2.1 RTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4056,
     "status": "ok",
     "timestamp": 1649275983249,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "iX9JfQKbNK8v",
    "outputId": "4e89e9e2-4bc4-4617-f9ed-e97b7d817850"
   },
   "outputs": [],
   "source": [
    "data, dtype = \"RTA\", \"original\"\n",
    "extract_data(file_pattern=os.path.join(C.RAW_DATA_PATTERN.format(data=data), \"*.mat\"), \n",
    "                   bscan_key='volumedata', \n",
    "                   layermap_key='Observer2',\n",
    "                   bscan_format='hws',\n",
    "                   layermap_format='wsl',\n",
    "                   layer_labels=RTA_LABELS,\n",
    "                   bscan_folder=C.BSCAN_PATTERN.format(data=data),\n",
    "                   layer_folder=C.LAYER_PATTERN.format(data=data, dtype=dtype),\n",
    "                   overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iN8ntIoENfZJ",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2.2.2 DME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14120,
     "status": "ok",
     "timestamp": 1649269478810,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "6jnf7swCNhqs",
    "outputId": "5c73382c-d260-483d-facc-97e4521b4219"
   },
   "outputs": [],
   "source": [
    "data, dtype = \"DME\", \"original\"\n",
    "extract_data(file_pattern=os.path.join(C.RAW_DATA_PATTERN.format(data=data), \"*.mat\"),\n",
    "                   bscan_key='images',\n",
    "                   layermap_key='manualLayers1',\n",
    "                   fluid_key='manualFluid1',\n",
    "                   bscan_format='hws',\n",
    "                   layermap_format='lws',\n",
    "                   layer_labels=DME_LABELS,\n",
    "                   bscan_folder=C.BSCAN_PATTERN.format(data=data),\n",
    "                   layer_folder=C.LAYER_PATTERN.format(data=data, dtype=dtype),\n",
    "                   fluid_folder=C.FLUID_PATTERN.format(data=data),\n",
    "                   valid_slice_indices_fn=get_dme_valid_idx,\n",
    "                   overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1oRBMyPNiFG",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2.2.3 AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3UgS7zkNlC8"
   },
   "outputs": [],
   "source": [
    "# Control data\n",
    "data, dtype = \"AMD\", \"original\"\n",
    "extract_data(file_pattern=os.path.join(C.RAW_DATA_PATTERN.format(data=data), 'Control 2/Control 2/*.mat'), \n",
    "                   bscan_key='images',\n",
    "                   layermap_key='layerMaps',\n",
    "                   bscan_format='hws',\n",
    "                   layermap_format='swl',\n",
    "                   layer_labels=AMD_LABELS,\n",
    "                   bscan_folder=C.BSCAN_PATTERN.format(data=data),\n",
    "                   layer_folder=C.LAYER_PATTERN.format(data=data, dtype=dtype),\n",
    "                   valid_slice_indices_fn=get_amd_valid_idx,\n",
    "                   overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "aborted",
     "timestamp": 1649276155211,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "jaUtxCK3JlEl"
   },
   "outputs": [],
   "source": [
    "# AMD data\n",
    "data, dtype = \"AMD\", \"original\"\n",
    "extract_data(file_pattern=os.path.join(C.RAW_DATA_PATTERN.format(data=data),'AMD 2/AMD 2/*.mat'), \n",
    "                   bscan_key='images',\n",
    "                   layermap_key='layerMaps',\n",
    "                   bscan_format='hws',\n",
    "                   layermap_format='swl',\n",
    "                   layer_labels=AMD_LABELS,\n",
    "                   bscan_folder=C.BSCAN_PATTERN.format(data=data),\n",
    "                   layer_folder=C.LAYER_PATTERN.format(data=data, dtype=dtype),\n",
    "                   valid_slice_indices_fn=get_amd_valid_idx,\n",
    "                   overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69I4rweZNleL",
    "tags": []
   },
   "source": [
    "### 2.2.4 AROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, dtype = \"AROI\", \"original\"\n",
    "extract_data_aroi(raw_data_folder=C.RAW_DATA_PATTERN.format(data=data),\n",
    "                        bscan_folder=C.BSCAN_PATTERN.format(data=data),\n",
    "                        layer_folder=C.LAYER_PATTERN.format(data=data, dtype=dtype),\n",
    "                        fluid_folder=C.FLUID_PATTERN.format(data=data),\n",
    "                        dtype=dtype,\n",
    "                        fluid_labels=FLUID_LABELS,\n",
    "                        layer_labels=AROI_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, dtype = \"OP\", \"original\"\n",
    "name = \"original\"\n",
    "\n",
    "extract_data_op(raw_data_folder=C.RAW_DATA_PATTERN.format(data=data),\n",
    "                bscan_folder=C.BSCAN_PATTERN.format(data=data),\n",
    "                layer_folder=C.LAYER_PATTERN.format(data=data, dtype=dtype),\n",
    "                layer_labels=OP_LABELS,\n",
    "                instrument_labels=INSTRUMENT_LABELS,\n",
    "                extension='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttr8-k4JND-E",
    "tags": []
   },
   "source": [
    "## 2.3 Reduced-Layer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocEvOnJ8PST_"
   },
   "source": [
    "### 2.3.1 RTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1998,
     "status": "ok",
     "timestamp": 1649268982887,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "Triifqs7PRm8",
    "outputId": "a6ffed52-5ad7-4e7d-b32b-db861f8bc67a"
   },
   "outputs": [],
   "source": [
    "data = \"RTA\"\n",
    "convert_to_dataset(file_pattern=os.path.join(C.RAW_DATA_PATTERN.format(data=data),'Subject[78]*.mat'), \n",
    "                   bscan_key='volumedata', \n",
    "                   layermap_key='Observer2',\n",
    "                   bscan_format='hws',\n",
    "                   layermap_format='wsl',\n",
    "                   layer_labels=RTA_LABELS,\n",
    "                   bscan_folder=C.BSCAN_PATTERN.format(data=data),\n",
    "                   layer_folder=C.LAYER_PATTERN.format(data=data, dtype='reduce1'),\n",
    "                   remove_from=range(2,8), # 6 out of 8\n",
    "                   n_remove=1)\n",
    "convert_to_dataset(file_pattern=os.path.join(C.RAW_DATA_PATTERN.format(data=data),'Subject[56]*.mat'), \n",
    "                   bscan_key='volumedata', \n",
    "                   layermap_key='Observer2',\n",
    "                   bscan_format='hws',\n",
    "                   layermap_format='wsl',\n",
    "                   layer_labels=RTA_LABELS,\n",
    "                   bscan_folder=C.BSCAN_PATTERN.format(data=data),\n",
    "                   layer_folder=C.LAYER_PATTERN.format(data=data, dtype='reduce2'),\n",
    "                   remove_from=range(2,8), # 6 out of 8\n",
    "                   n_remove=2)\n",
    "convert_to_dataset(file_pattern=os.path.join(C.RAW_DATA_PATTERN.format(data=data),'Subject[34]*.mat'), \n",
    "                   bscan_key='volumedata', \n",
    "                   layermap_key='Observer2',\n",
    "                   bscan_format='hws',\n",
    "                   layermap_format='wsl',\n",
    "                   layer_labels=RTA_LABELS,\n",
    "                   bscan_folder=C.BSCAN_PATTERN.format(data=data),\n",
    "                   layer_folder=C.LAYER_PATTERN.format(data=data, dtype='reduce3'),\n",
    "                   remove_from=range(2,8), # 6 out of 8\n",
    "                   n_remove=3)\n",
    "convert_to_dataset(file_pattern=os.path.join(C.RAW_DATA_PATTERN.format(data=data),'Subject[12]*.mat'), \n",
    "                   bscan_key='volumedata', \n",
    "                   layermap_key='Observer2',\n",
    "                   bscan_format='hws',\n",
    "                   layermap_format='wsl',\n",
    "                   layer_labels=RTA_LABELS,\n",
    "                   bscan_folder=C.BSCAN_PATTERN.format(data=data),\n",
    "                   layer_folder=C.LAYER_PATTERN.format(data=data, dtype='reduce4'),\n",
    "                   remove_from=range(2,8), # 6 out of 8\n",
    "                   n_remove=4)\n",
    "convert_to_dataset(file_pattern=os.path.join(C.RAW_DATA_PATTERN.format(data=data),'Subject[12]*.mat'), \n",
    "                   bscan_key='volumedata', \n",
    "                   layermap_key='Observer2',\n",
    "                   bscan_format='hws',\n",
    "                   layermap_format='wsl',\n",
    "                   layer_labels=RTA_LABELS,\n",
    "                   bscan_folder=C.BSCAN_PATTERN.format(data=data),\n",
    "                   layer_folder=C.LAYER_PATTERN.format(data=data, dtype='reduce5'),\n",
    "                   remove_from=range(2,8), # 6 out of 8\n",
    "                   n_remove=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsGkSrPAPYko",
    "tags": []
   },
   "source": [
    "### 2.3.2 DME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12151,
     "status": "ok",
     "timestamp": 1649269028258,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "oTNmSVz2Png2",
    "outputId": "c6bd4f8f-acde-4e3e-8eec-183849b56d0a"
   },
   "outputs": [],
   "source": [
    "data = \"DME\"\n",
    "convert_to_dataset(file_pattern=os.path.join(C.RAW_DATA_PATTERN.format(data=data),'Subject_0[89].mat'),\n",
    "                   bscan_key='images',\n",
    "                   layermap_key='manualLayers1',\n",
    "                   fluid_key='manualFluid1',\n",
    "                   bscan_format='hws',\n",
    "                   layermap_format='lws',\n",
    "                   layer_labels=DME_LABELS,\n",
    "                   bscan_folder=C.BSCAN_PATTERN.format(data=data),\n",
    "                   layer_folder=C.LAYER_PATTERN.format(data=data, dtype='reduce1'),\n",
    "                   fluid_folder=C.FLUID_PATTERN.format(data=data),\n",
    "                   valid_slice_indices_fn=get_dme_valid_idx,\n",
    "                   remove_from=range(2,8), # DME also has 8 layers, we choose 6 out of 8\n",
    "                   n_remove=1)\n",
    "convert_to_dataset(file_pattern=os.path.join(C.RAW_DATA_PATTERN.format(data=data),'Subject_0[67].mat'),\n",
    "                   bscan_key='images',\n",
    "                   layermap_key='manualLayers1',\n",
    "                   fluid_key='manualFluid1',\n",
    "                   bscan_format='hws',\n",
    "                   layermap_format='lws',\n",
    "                   layer_labels=DME_LABELS,\n",
    "                   bscan_folder=C.BSCAN_PATTERN.format(data=data),\n",
    "                   layer_folder=C.LAYER_PATTERN.format(data=data, dtype='reduce2'),\n",
    "                   fluid_folder=C.FLUID_PATTERN.format(data=data),\n",
    "                   valid_slice_indices_fn=get_dme_valid_idx,\n",
    "                   remove_from=range(2,8), # DME also has 8 layers, we choose 6 out of 8\n",
    "                   n_remove=2)\n",
    "convert_to_dataset(file_pattern=os.path.join(C.RAW_DATA_PATTERN.format(data=data),'Subject_0[45].mat'),\n",
    "                   bscan_key='images',\n",
    "                   layermap_key='manualLayers1',\n",
    "                   fluid_key='manualFluid1',\n",
    "                   bscan_format='hws',\n",
    "                   layermap_format='lws',\n",
    "                   layer_labels=DME_LABELS,\n",
    "                   bscan_folder=C.BSCAN_PATTERN.format(data=data),\n",
    "                   layer_folder=C.LAYER_PATTERN.format(data=data, dtype='reduce3'),\n",
    "                   fluid_folder=C.FLUID_PATTERN.format(data=data),\n",
    "                   valid_slice_indices_fn=get_dme_valid_idx,\n",
    "                   remove_from=range(2,8), # DME also has 8 layers, we choose 6 out of 8\n",
    "                   n_remove=3)\n",
    "convert_to_dataset(file_pattern=os.path.join(C.RAW_DATA_PATTERN.format(data=data),'Subject_0[23].mat'),\n",
    "                   bscan_key='images',\n",
    "                   layermap_key='manualLayers1',\n",
    "                   fluid_key='manualFluid1',\n",
    "                   bscan_format='hws',\n",
    "                   layermap_format='lws',\n",
    "                   layer_labels=DME_LABELS,\n",
    "                   bscan_folder=C.BSCAN_PATTERN.format(data=data),\n",
    "                   layer_folder=C.LAYER_PATTERN.format(data=data, dtype='reduce4'),\n",
    "                   fluid_folder=C.FLUID_PATTERN.format(data=data),\n",
    "                   valid_slice_indices_fn=get_dme_valid_idx,\n",
    "                   remove_from=range(2,8), # DME also has 8 layers, we choose 6 out of 8\n",
    "                   n_remove=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmvbhX9CPb6i"
   },
   "source": [
    "### 2.3.3 AMD\n",
    "\n",
    "There are only 3 layers within it. Let it go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4xts5XdwPn7Z"
   },
   "outputs": [],
   "source": [
    "data = 'AMD'\n",
    "dtype = 'reduce1'\n",
    "convert_to_dataset_AROI(raw_data_folder=C.RAW_DATA_PATTERN.format(data=data),\n",
    "                        bscan_folder=C.BSCAN_PATTERN.format(data=data),\n",
    "                        layer_folder=C.LAYER_PATTERN.format(data=data, dtype=dtype),\n",
    "                        fluid_folder=C.FLUID_PATTERN.format(data=data),\n",
    "                        dtype=dtype,\n",
    "                        fluid_labels=FLUID_LABELS,\n",
    "                        layer_labels=AROI_LABELS,\n",
    "                        remove_from=range(1,3),\n",
    "                        n_remove=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czhJCeIePiI1"
   },
   "source": [
    "### 2.3.4 AROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "5uwDJda2Mhj7"
   },
   "outputs": [],
   "source": [
    "data = 'AROI'\n",
    "dtype = 'reduce1'\n",
    "convert_to_dataset_AROI(raw_data_folder=C.RAW_DATA_PATTERN.format(data=data),\n",
    "                        bscan_folder=C.BSCAN_PATTERN.format(data=data),\n",
    "                        layer_folder=C.LAYER_PATTERN.format(data=data, dtype=dtype),\n",
    "                        fluid_folder=C.FLUID_PATTERN.format(data=data),\n",
    "                        dtype=dtype,\n",
    "                        fluid_labels=FLUID_LABELS,\n",
    "                        layer_labels=AROI_LABELS,\n",
    "                        remove_from=range(1,3),\n",
    "                        n_remove=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gy7tSqvJQ_Yk"
   },
   "source": [
    "# 3 Split Data into train, val and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xN28uBYqRXqc"
   },
   "source": [
    "## 3.1 Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name(f, extension='jpg'):\n",
    "    ''' extract the original name of f '''\n",
    "    pattern = r\"(.+)_del.+\"\n",
    "    f_original = re.match(pattern, f).group(1) + \".\" + extension\n",
    "    return f_original\n",
    "    \n",
    "def split_files(file_names, train_ratio, test_ratio):\n",
    "    ''' split file names into train, val, test and return as a dictionary'''\n",
    "    random.shuffle(file_names)\n",
    "    \n",
    "    num_train = int(len(file_names) * train_ratio)\n",
    "    num_test = int(len(file_names) * test_ratio)\n",
    "    \n",
    "    train_files = file_names[:num_train]\n",
    "    test_files = file_names[num_train:num_train+num_test]\n",
    "    val_files = file_names[num_train+num_test:]\n",
    "    \n",
    "    splited_files = { 'train': train_files, 'test': test_files, 'val': val_files}\n",
    "    return splited_files\n",
    "\n",
    "def generate_label(layer_path, fluid_path):\n",
    "    ''' combine layer and fluid as label'''\n",
    "    layer = imageio.imread(layer_path)\n",
    "    fluid = imageio.imread(fluid_path)\n",
    "    \n",
    "    label = np.where(layer > 0, layer, fluid)\n",
    "    label_img = Image.fromarray(label)\n",
    "    return label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1649278284310,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "uta9O-BFRIbX"
   },
   "outputs": [],
   "source": [
    "def prepare_files(data, dst_folder, train_ratio, test_ratio,\n",
    "                  with_fluids=True, dtype=\"original\", merge_original=False,\n",
    "                 extension='jpg'):\n",
    "    ''' output: splitted version of files (labels & bscans) with train, val, test\n",
    "        args:\n",
    "            data: str, name of data \n",
    "            dst_folder: destination folder\n",
    "            train_ration, test_ration: obvious\n",
    "            with_fluids: whether the dataset contains fluids\n",
    "            dtype: str, name of type of layeys (e.g. could be reduced layers), by default \"original\"\n",
    "            merge_original: whether to contain original data with original layers for reduced layers\n",
    "    '''\n",
    "    formatted_pattern = C.BSCAN_PATTERN.format(data=data) if dtype == 'original' \\\n",
    "        else C.LAYER_PATTERN.format(data=data, dtype=dtype)\n",
    "    files_pattern = os.path.join(formatted_pattern, '*.' + extension)\n",
    "    files = glob(files_pattern)\n",
    "    print(f\"[INFO] {len(files)} files matches pattern {files_pattern}\")\n",
    "        \n",
    "    file_names = [f.split('/')[-1] for f in files]\n",
    "    \n",
    "    train_ratio, test_ratio = 0.8, 0.1\n",
    "    splited_files = split_files(file_names, train_ratio, test_ratio)\n",
    "            \n",
    "    src_bscan_folder = C.BSCAN_PATTERN.format(data=data)\n",
    "    src_layer_folder = C.LAYER_PATTERN.format(data=data, dtype=dtype)\n",
    "    if with_fluids:\n",
    "        src_fluid_folder = C.FLUID_PATTERN.format(data=data)\n",
    "    \n",
    "    for mode in ['train', 'test', 'val']:\n",
    "        print(f\"Preparing {mode} files:\")\n",
    "        \n",
    "        dst_label_folder = os.path.join(dst_folder, 'labels', mode)\n",
    "        Path(dst_label_folder).mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"created dst label folder {dst_label_folder}\")\n",
    "        \n",
    "        dst_bscan_folder = os.path.join(dst_folder, 'bscans', mode)\n",
    "        Path(dst_bscan_folder).mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"created dst bscan folder {dst_bscan_folder}\")\n",
    "        \n",
    "        for f in tqdm(splited_files[mode]):\n",
    "            \n",
    "            f_original = extract_name(f, extension) if dtype!=\"original\" else f\n",
    "            \n",
    "            #### Paths with name f ####\n",
    "            src_layer_path = os.path.join(src_layer_folder, f)\n",
    "\n",
    "            dst_label_path = os.path.join(dst_label_folder, f)\n",
    "\n",
    "            dst_bscan_path = os.path.join(dst_bscan_folder, f)\n",
    "                \n",
    "            #### Paths with the original name of f ####\n",
    "            src_bscan_path = os.path.join(src_bscan_folder, f_original)\n",
    "            \n",
    "            if with_fluids:\n",
    "                src_fluid_path = os.path.join(src_fluid_folder, f_original)\n",
    "            \n",
    "            #### if merge: bscans & labels of f original ####\n",
    "            if dtype != \"original\" and merge_original:\n",
    "                # bscan path of f_original\n",
    "                src_original_bscan_path = src_bscan_path\n",
    "                dst_original_bscan_path = os.path.join(dst_bscan_folder, f_original)\n",
    "                \n",
    "                # label paths of f_original\n",
    "                src_original_layer_folder = C.LAYER_PATTERN.format(data=data, dtype=\"original\")\n",
    "                src_original_layer_path = os.path.join(src_original_layer_folder, f_original)\n",
    "                dst_original_label_path = os.path.join(dst_label_folder, f_original)\n",
    "                \n",
    "                if not Path(src_original_bscan_path).exists():\n",
    "                    print(f\"[WARN] src original B-scan does not exist for {f_original}\")\n",
    "                    continue\n",
    "                if not Path(src_original_layer_path).exists():\n",
    "                    print(f\"[WARN] src original layer does not exist for {f_original}\")\n",
    "                    continue\n",
    "                    \n",
    "                # copy bscan of f original \n",
    "                # (given that if merge, moving twice would result in error, here assume enough space)\n",
    "                shutil.copy(src_original_bscan_path, dst_original_bscan_path)\n",
    "                \n",
    "                # save(with fluids) or move(without fluids) label of f original\n",
    "                if with_fluids: # label = layer + fluid\n",
    "                    if not Path(src_fluid_path).exists():\n",
    "                        print(f\"[WARN] src fluid does not exist for {f_original}\")\n",
    "                    label_original_img = generate_label(src_original_layer_path, src_fluid_path)\n",
    "                    label_original_img.save(dst_original_label_path)     \n",
    "                else: #layer\n",
    "                    shutil.copy(src_original_layer_path, dst_original_label_path)\n",
    "                \n",
    "                if not Path(dst_original_bscan_path).exists() or not Path(dst_original_label_path).exists():\n",
    "                    print(f\"[WARN] dst original B-scan or label does not exist for {f_original}\")\n",
    "                    \n",
    "\n",
    "            #### bscans & labels of f ####\n",
    "            if not Path(src_bscan_path).exists(): \n",
    "                print(f\"[WARN] src B-scan does not exist for {f}\")\n",
    "                continue\n",
    "            if not Path(src_layer_path).exists():\n",
    "                print(f\"[WARN] src layer does not exist for {f}\")\n",
    "                continue\n",
    "            \n",
    "            # move bscan of f\n",
    "            shutil.copy(src_bscan_path, dst_bscan_path)\n",
    "\n",
    "            # save(with fluids) or move(without fluids) label of f \n",
    "            if with_fluids: # label = fluid + layer\n",
    "                if not Path(src_fluid_path).exists():\n",
    "                    print(f\"[WARN] src fluid does not exist for {f}\")\n",
    "                label_img = generate_label(src_layer_path, src_fluid_path)\n",
    "                label_img.save(dst_label_path)\n",
    "            else: # layer\n",
    "                shutil.copy(src_layer_path, dst_label_path)\n",
    "                \n",
    "            if not Path(dst_bscan_path).exists() or not Path(dst_label_path).exists():\n",
    "                print(f\"[WARN] dst B-scan or label does not exist for {f}\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9jXPaTcSm-C",
    "tags": []
   },
   "source": [
    "## 3.2 Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbnXzvJMSrDm",
    "tags": []
   },
   "source": [
    "### 3.2.1 RTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, dtype = \"RTA\", \"original\"\n",
    "name = \"original\"\n",
    "\n",
    "prepare_files(data=data, \n",
    "              dst_folder=C.SPLIT_PATTERN.format(data=data, name=name), \n",
    "              train_ratio=0.8, \n",
    "              test_ratio=0.1,\n",
    "              with_fluids=False,\n",
    "              dtype=dtype  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQLMPJvfS39O",
    "tags": []
   },
   "source": [
    "### 3.2.2 DME\n",
    "\n",
    "Just a backup for original code\n",
    "```python\n",
    "bscan_files = glob(C.DME_BSCAN_ORIGINAL_FOLDER + '*.jpg')\n",
    "assert len(bscan_files) != 0\n",
    "\n",
    "train_files, test_files, val_files = split_files(bscan_files, 0.8, 0.1)\n",
    "assert len(train_files) != 0, f\"train_files is empty, data may have already been moved\"\n",
    "\n",
    "splited_files = {\n",
    "    'train': train_files,\n",
    "    'test': test_files,\n",
    "    'val': val_files\n",
    "}\n",
    "move_files(splited_files, C.DME_LAYER_BSCAN_ORIGINAL_ROOT, C.DME_SPLIT_ORIGINAL_FOLDER)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1310,
     "status": "ok",
     "timestamp": 1649276015123,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "1kZrkt_5S908"
   },
   "outputs": [],
   "source": [
    "data, dtype = \"DME\", \"original\"\n",
    "name = \"original\"\n",
    "\n",
    "prepare_files(data=data, \n",
    "              dst_folder=C.SPLIT_PATTERN.format(data=data, name=name), \n",
    "              train_ratio=0.8, \n",
    "              test_ratio=0.1,\n",
    "              with_fluids=True,\n",
    "              dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvkW-qBKTCkY",
    "tags": []
   },
   "source": [
    "### 3.2.3 AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 182787,
     "status": "ok",
     "timestamp": 1649278102271,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "SKYMcDTznxrv",
    "outputId": "d31dac7e-a8df-4a0b-d217-190088b9ec15"
   },
   "outputs": [],
   "source": [
    "# # Move back\n",
    "# !mv ./data/splits/original/AMD/bscans/train/Farsiu_* $C.AMD_BSCAN_ORIGINAL_FOLDER\n",
    "# !mv ./data/splits/original/AMD/bscans/test/Farsiu_* $C.AMD_BSCAN_ORIGINAL_FOLDER\n",
    "# !mv ./data/splits/original/AMD/bscans/val/Farsiu_* $C.AMD_BSCAN_ORIGINAL_FOLDER\n",
    "# !mv ./data/splits/original/AMD/layers/train/Farsiu_* $C.AMD_LAYER_ORIGINAL_FOLDER\n",
    "# !mv ./data/splits/original/AMD/layers/test/Farsiu_* $C.AMD_LAYER_ORIGINAL_FOLDER\n",
    "# !mv ./data/splits/original/AMD/layers/val/Farsiu_* $C.AMD_LAYER_ORIGINAL_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1104,
     "status": "ok",
     "timestamp": 1649278510189,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "Cp41Wtm3TEyc",
    "outputId": "2460c0b3-96b4-45e0-9594-f0d5f3c78b7c"
   },
   "outputs": [],
   "source": [
    "# bscan_files = glob(C.AMD_BSCAN_ORIGINAL_FOLDER + '*.jpg')\n",
    "# print(len(bscan_files))\n",
    "\n",
    "# train_files, test_files, val_files = split_files(bscan_files, 0.8, 0.1)\n",
    "# assert len(train_files) != 0, f\"train_files is empty, data may have already been moved\"\n",
    "\n",
    "# splited_files = {\n",
    "#    'train': train_files,\n",
    "#    'test': test_files,\n",
    "#    'val': val_files\n",
    "# }\n",
    "# move_files(splited_files, C.AMD_LAYER_BSCAN_ORIGINAL_ROOT, C.AMD_SPLIT_ORIGINAL_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, dtype = \"AMD\", \"original\"\n",
    "name = \"original\"\n",
    "\n",
    "prepare_files(data=data, \n",
    "              dst_folder=C.SPLIT_PATTERN.format(data=data, name=name), \n",
    "              train_ratio=0.8, \n",
    "              test_ratio=0.1,\n",
    "              with_fluids=False,\n",
    "              dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RpQqPH9TLKC",
    "tags": []
   },
   "source": [
    "### 3.2.4 AROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, dtype = \"AROI\", \"original\"\n",
    "name = \"original\"\n",
    "\n",
    "prepare_files(data=data, \n",
    "              dst_folder=C.SPLIT_PATTERN.format(data=data, name=name), \n",
    "              train_ratio=0.8, \n",
    "              test_ratio=0.1,\n",
    "              with_fluids=True,\n",
    "              dtype=dtype,\n",
    "              extension='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5 OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, dtype = \"OP\", \"original\"\n",
    "name = \"original\"\n",
    "\n",
    "prepare_files(data=data, \n",
    "              dst_folder=C.SPLIT_PATTERN.format(data=data, name=name), \n",
    "              train_ratio=0.8, \n",
    "              test_ratio=0.1,\n",
    "              with_fluids=False,\n",
    "              dtype=dtype,\n",
    "              extension='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RARNt_luTUKB",
    "tags": []
   },
   "source": [
    "## 3.3 Reduced-Layer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBED9BKETY2m",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.3.1 RTA\n",
    "\n",
    "just another backup:\n",
    "```python\n",
    "bscan_files = glob(C.RTA_BSCAN_REDUCED_FOLDER+'*.jpg')\n",
    "print(len(bscan_files))\n",
    "\n",
    "train_files, test_files, val_files = split_files(bscan_files, 0.8, 0.1)\n",
    "assert len(train_files) != 0, f\"train_files is empty, data may have already been moved\"\n",
    "\n",
    "splited_files = {\n",
    "    'train': train_files,\n",
    "    'test': test_files,\n",
    "    'val': val_files\n",
    "}\n",
    "move_files(splited_files, C.RTA_LAYER_BSCAN_REDUCED_ROOT, C.RTA_SPLIT_REDUCED_FOLDER)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"RTA\"\n",
    "name = \"reduce_merge\"\n",
    "\n",
    "prepare_files(data=data, \n",
    "              dst_folder=C.SPLIT_PATTERN.format(data=data, name=name), \n",
    "              train_ratio=0.8, \n",
    "              test_ratio=0.1,\n",
    "              with_fluids=False,\n",
    "              dtype=\"reduce1\", \n",
    "              merge_original=True)\n",
    "prepare_files(data=data, \n",
    "              dst_folder=C.SPLIT_PATTERN.format(data=data, name=name), \n",
    "              train_ratio=0.8, \n",
    "              test_ratio=0.1,\n",
    "              with_fluids=False,\n",
    "              dtype=\"reduce2\", \n",
    "              merge_original=True)\n",
    "prepare_files(data=data, \n",
    "              dst_folder=C.SPLIT_PATTERN.format(data=data, name=name), \n",
    "              train_ratio=0.8, \n",
    "              test_ratio=0.1,\n",
    "              with_fluids=False,\n",
    "              dtype=\"reduce3\", \n",
    "              merge_original=True)\n",
    "prepare_files(data=data, \n",
    "              dst_folder=C.SPLIT_PATTERN.format(data=data, name=name), \n",
    "              train_ratio=0.8, \n",
    "              test_ratio=0.1,\n",
    "              with_fluids=False,\n",
    "              dtype=\"reduce4\", \n",
    "              merge_original=True)\n",
    "prepare_files(data=data, \n",
    "              dst_folder=C.SPLIT_PATTERN.format(data=data, name=name), \n",
    "              train_ratio=0.8, \n",
    "              test_ratio=0.1,\n",
    "              with_fluids=False,\n",
    "              dtype=\"reduce5\", \n",
    "              merge_original=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvLvc_lSTaL-"
   },
   "source": [
    "### 3.3.2 DME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"DME\"\n",
    "name = \"reduce_merge\"\n",
    "\n",
    "prepare_files(data=data, \n",
    "              dst_folder=C.SPLIT_PATTERN.format(data=data, name=name), \n",
    "              train_ratio=0.8, \n",
    "              test_ratio=0.1,\n",
    "              with_fluids=True,\n",
    "              dtype=\"reduce1\", \n",
    "              merge_original=True)\n",
    "prepare_files(data=data, \n",
    "              dst_folder=C.SPLIT_PATTERN.format(data=data, name=name), \n",
    "              train_ratio=0.8, \n",
    "              test_ratio=0.1,\n",
    "              with_fluids=True,\n",
    "              dtype=\"reduce2\", \n",
    "              merge_original=True)\n",
    "prepare_files(data=data, \n",
    "              dst_folder=C.SPLIT_PATTERN.format(data=data, name=name), \n",
    "              train_ratio=0.8, \n",
    "              test_ratio=0.1,\n",
    "              with_fluids=True,\n",
    "              dtype=\"reduce3\", \n",
    "              merge_original=True)\n",
    "prepare_files(data=data, \n",
    "              dst_folder=C.SPLIT_PATTERN.format(data=data, name=name), \n",
    "              train_ratio=0.8, \n",
    "              test_ratio=0.1,\n",
    "              with_fluids=True,\n",
    "              dtype=\"reduce4\", \n",
    "              merge_original=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smwA3LuTTdOg",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.3.3 AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1649279035143,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "cAFYZVOiTXSn",
    "outputId": "4d2976fc-6b75-415d-856c-80eb12185263"
   },
   "outputs": [],
   "source": [
    "bscan_files = glob(C.DME_BSCAN_REDUCED_FOLDER+'*.jpg')\n",
    "print(len(bscan_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6JNEi64UA7M"
   },
   "outputs": [],
   "source": [
    "train_files, test_files, val_files = split_files(bscan_files, 0.8, 0.1)\n",
    "assert len(train_files) != 0, f\"train_files is empty, data may have already been moved\"\n",
    "\n",
    "splited_files = {\n",
    "    'train': train_files,\n",
    "    'test': test_files,\n",
    "    'val': val_files\n",
    "}\n",
    "move_files(splited_files, C.AMD_LAYER_BSCAN_REDUCED_ROOT, C.AMD_SPLIT_REDUCED_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmgakK95Te0c",
    "tags": []
   },
   "source": [
    "### 3.3.4 AROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, dtype = \"AROI\", \"reduce1\"\n",
    "name = \"reduce1_merge\"\n",
    "merge_original = True\n",
    "\n",
    "prepare_files(data=data, \n",
    "              dst_folder=C.SPLIT_PATTERN.format(data=data, name=name), \n",
    "              train_ratio=0.8, \n",
    "              test_ratio=0.1,\n",
    "              with_fluids=True,\n",
    "              dtype=dtype, \n",
    "              merge_original=merge_original,\n",
    "              extension='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KGFVM3zUMKT"
   },
   "source": [
    "# 4 Create pix2pix Compatible Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZ66rERnUUWE",
    "tags": []
   },
   "source": [
    "## 4.1 Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mN61JQ38Uax5",
    "tags": []
   },
   "source": [
    "### 4.1.1 RTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23164,
     "status": "ok",
     "timestamp": 1649279146847,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "Mgj9hl30UI3E",
    "outputId": "01ca2c76-7a0c-4b08-b1be-b3b16ac942d1"
   },
   "outputs": [],
   "source": [
    "label_folder = C.SPLIT_PATTERN.format(data='RTA', name='original') + '/labels'\n",
    "bscan_folder = C.SPLIT_PATTERN.format(data='RTA', name='original') + '/bscans'\n",
    "dataset_folder = C.DATASET_PATTERN.format(data='RTA', name='original')\n",
    "!python pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py --fold_A $label_folder --fold_B $bscan_folder --fold_AB $dataset_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnjaMmczUgBj",
    "tags": []
   },
   "source": [
    "### 4.1.2 DME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24149,
     "status": "ok",
     "timestamp": 1649279205431,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "YeHdsbT1UK8b",
    "outputId": "ef50a858-da8f-46ca-bb99-e65655a39a96"
   },
   "outputs": [],
   "source": [
    "label_folder = C.SPLIT_PATTERN.format(data='DME', name='original') + '/labels'\n",
    "bscan_folder = C.SPLIT_PATTERN.format(data='DME', name='original') + '/bscans'\n",
    "dataset_folder = C.DATASET_PATTERN.format(data='DME', name='original')\n",
    "!python pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py \\\n",
    "    --fold_A $label_folder \\\n",
    "    --fold_B $bscan_folder \\\n",
    "    --fold_AB $dataset_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2xsX8W-UiFx",
    "tags": []
   },
   "source": [
    "### 4.1.3 AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1123894,
     "status": "ok",
     "timestamp": 1649280333227,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "RA2nzPvkUmcq",
    "outputId": "f8f2ffee-e500-4407-846c-254167956c50"
   },
   "outputs": [],
   "source": [
    "label_folder = C.SPLIT_PATTERN.format(data='AMD', name='original') + '/labels'\n",
    "bscan_folder = C.SPLIT_PATTERN.format(data='AMD', name='original') + '/bscans'\n",
    "dataset_folder = C.DATASET_PATTERN.format(data='AMD', name='original')\n",
    "!python pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py --fold_A $label_folder --fold_B $bscan_folder --fold_AB $dataset_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5294,
     "status": "ok",
     "timestamp": 1649280946177,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "ctH4O8-EyAkd",
    "outputId": "9985a15f-6088-48c8-ebda-9f37765cd204"
   },
   "outputs": [],
   "source": [
    "# delete generated AMD datasets\n",
    "!rm $dataset_folder/test/Farsiu_*\n",
    "!rm $dataset_folder/train/Farsiu_*\n",
    "!rm $dataset_folder/val/Farsiu_*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWWgeVvwUm38"
   },
   "source": [
    "### 4.1.4 AROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_folder = C.SPLIT_PATTERN.format(data='AROI', name='original') + '/labels'\n",
    "bscan_folder = C.SPLIT_PATTERN.format(data='AROI', name='original') + '/bscans'\n",
    "dataset_folder = C.DATASET_PATTERN.format(data='AROI', name='original')\n",
    "!python pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py \\\n",
    "    --fold_A $label_folder \\\n",
    "    --fold_B $bscan_folder \\\n",
    "    --fold_AB $dataset_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5 OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_folder = C.SPLIT_PATTERN.format(data='OP', name='original') + '/labels'\n",
    "bscan_folder = C.SPLIT_PATTERN.format(data='OP', name='original') + '/bscans'\n",
    "dataset_folder = C.DATASET_PATTERN.format(data='OP', name='original')\n",
    "!python pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py \\\n",
    "    --fold_A $label_folder \\\n",
    "    --fold_B $bscan_folder \\\n",
    "    --fold_AB $dataset_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qigV5v4zU1sZ",
    "tags": []
   },
   "source": [
    "## 4.2 Reduced-Layer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_e1O-9OU9Ls",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 4.2.1 RTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34100,
     "status": "ok",
     "timestamp": 1649281131415,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "tFWLtO4kU6iO",
    "outputId": "d4980c84-8096-4b12-99bb-6b0591a3fdee"
   },
   "outputs": [],
   "source": [
    "data, name = \"RTA\", \"reduce_merge\"\n",
    "bscan_folder = os.path.join(C.SPLIT_PATTERN.format(data=data, name=name), \"bscans\")\n",
    "label_folder = os.path.join(C.SPLIT_PATTERN.format(data=data, name=name), \"labels\")\n",
    "dataset_folder = C.DATASET_PATTERN.format(data=data, name=name)\n",
    "\n",
    "!python pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py \\\n",
    "    --fold_A $label_folder \\\n",
    "    --fold_B $bscan_folder \\\n",
    "    --fold_AB $dataset_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0KysNxsVG7-",
    "tags": []
   },
   "source": [
    "### 4.2.2 DME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45593,
     "status": "ok",
     "timestamp": 1649281177003,
     "user": {
      "displayName": "Yuanchun",
      "userId": "14461537273961936529"
     },
     "user_tz": -120
    },
    "id": "mw5v2jFAU4R_",
    "outputId": "cbdcd6bb-5086-43fa-d553-6f6349e17fe4"
   },
   "outputs": [],
   "source": [
    "data, name = \"DME\", \"reduce_merge\"\n",
    "bscan_folder = os.path.join(C.SPLIT_PATTERN.format(data=data, name=name), \"bscans\")\n",
    "label_folder = os.path.join(C.SPLIT_PATTERN.format(data=data, name=name), \"labels\")\n",
    "dataset_folder = C.DATASET_PATTERN.format(data=data, name=name)\n",
    "\n",
    "!python pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py \\\n",
    "    --fold_A $label_folder \\\n",
    "    --fold_B $bscan_folder \\\n",
    "    --fold_AB $dataset_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kxumy7aGVKbt",
    "tags": []
   },
   "source": [
    "### 4.2.3 AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGnL1vsRVMZW"
   },
   "outputs": [],
   "source": [
    "data, name = \"AMD\", \"reduce_merge\"\n",
    "bscan_folder = os.path.join(C.SPLIT_PATTERN.format(data=data, name=name), \"bscans\")\n",
    "label_folder = os.path.join(C.SPLIT_PATTERN.format(data=data, name=name), \"labels\")\n",
    "dataset_folder = C.DATASET_PATTERN.format(data=data, name=name)\n",
    "\n",
    "!python pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py \\\n",
    "    --fold_A $label_folder \\\n",
    "    --fold_B $bscan_folder \\\n",
    "    --fold_AB $dataset_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPDOCFExVNqE"
   },
   "source": [
    "### 4.2.4 AROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, name = \"AROI\", \"reduce1_merge\"\n",
    "\n",
    "bscan_folder = os.path.join(C.SPLIT_PATTERN.format(data=data, name=name), \"bscans\")\n",
    "label_folder = os.path.join(C.SPLIT_PATTERN.format(data=data, name=name), \"labels\")\n",
    "dataset_folder = C.DATASET_PATTERN.format(data=data, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iextlvmWVPjD"
   },
   "outputs": [],
   "source": [
    "!python pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py \\\n",
    "    --fold_A \"$label_folder\" \\\n",
    "    --fold_B \"$bscan_folder\" \\\n",
    "    --fold_AB \"$dataset_folder\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lGbJHLeDIK6u"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "p2l3zVo-LVRO",
    "j-Kilc7tLg6u",
    "HZh3WsSnQEQc",
    "M9PaKEHPNPFu",
    "iN8ntIoENfZJ",
    "h1oRBMyPNiFG",
    "69I4rweZNleL",
    "ocEvOnJ8PST_",
    "lsGkSrPAPYko",
    "xN28uBYqRXqc",
    "nbnXzvJMSrDm",
    "VQLMPJvfS39O",
    "6RpQqPH9TLKC",
    "RARNt_luTUKB",
    "RBED9BKETY2m",
    "fvLvc_lSTaL-",
    "smwA3LuTTdOg",
    "AmgakK95Te0c",
    "7KGFVM3zUMKT",
    "mN61JQ38Uax5",
    "AnjaMmczUgBj",
    "v2xsX8W-UiFx",
    "uWWgeVvwUm38",
    "2_e1O-9OU9Ls",
    "G0KysNxsVG7-"
   ],
   "name": "Data Processing.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "341eb00c4a9278ff831ee92c03245caab542deedbe9556143b586a9f4837c15e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
